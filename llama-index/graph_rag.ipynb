{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahithkarra/Development/calpoly/csc481/agentic-rag/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core import StorageContext\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "Settings.llm = OpenAI(model=\"gpt-4.1-mini\")\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data').load_data()\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents=documents,\n",
    "    max_triplets_per_chunk=3,\n",
    "    storage_context=storage_context,\n",
    "    include_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipeSwitch is a system designed to enable GPU-efficient fine-grained time-sharing for multiple deep learning applications, achieving millisecond-scale context switching latencies and high throughput. It addresses the challenge of high overhead in switching tasks on GPUs by introducing pipelined context switching, which leverages the layered structure of neural network models to pipeline model transmission over PCIe and task execution on the GPU.\n",
      "\n",
      "Regarding GPU memory management, PipeSwitch employs a dedicated memory daemon that pre-allocates GPU memory and dynamically allocates it to worker processes at runtime. This approach minimizes the overhead of GPU memory allocation by avoiding repeated calls to expensive GPU memory management functions. The memory daemon stores each deep neural network model only once in host memory, reducing memory footprint, and directly transmits models to GPU memory for task startup, eliminating extra memory copies. Additionally, PipeSwitch uses unified memory management tailored for deep learning applications, which efficiently handles memory allocation and recycling of intermediate results without causing fragmentation. This memory management strategy is integral to PipeSwitch's ability to achieve fast task switching and high GPU utilization while maintaining process-level isolation.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode =\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5\n",
    ")\n",
    "response = query_engine.query(\"What is pipeswitch and how does it relate to GPU memory management?\")\n",
    "\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
