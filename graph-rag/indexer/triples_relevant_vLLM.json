[
  {
    "subject": "EFFICIENT MEMORY MANAGEMENT FOR LARGE LANGUAGE MODEL SERVING WITH PAGEDATTENTION",
    "predicate": "is authored by",
    "object": "WOOSUK KWON, ZHUOHAN LI, SIYUAN ZHUANG, YING SHENG, LIANMIN ZHENG, CODY HAO YU, JOSEPH E. GONZALEZ, HAO ZHANG, ION STOICA"
  },
  {
    "subject": "WOOSUK KWON",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "ZHUOHAN LI",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "SIYUAN ZHUANG",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "YING SHENG",
    "predicate": "affiliated with",
    "object": "UC BERKELEY and STANFORD UNIVERSITY"
  },
  {
    "subject": "LIANMIN ZHENG",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "CODY HAO YU",
    "predicate": "affiliated with",
    "object": "INDEPENDENT RESEARCHER"
  },
  {
    "subject": "JOSEPH E. GONZALEZ",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "HAO ZHANG",
    "predicate": "affiliated with",
    "object": "UC SAN DIEGO"
  },
  {
    "subject": "ION STOICA",
    "predicate": "affiliated with",
    "object": "UC BERKELEY"
  },
  {
    "subject": "HIGH THROUGHPUT SERVING OF LARGE LANGUAGE MODELS (LLMS)",
    "predicate": "requires",
    "object": "batching sufficiently many requests at a time"
  },
  {
    "subject": "existing systems",
    "predicate": "struggle because",
    "object": "the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically"
  },
  {
    "subject": "KV cache size",
    "predicate": "grows quickly with",
    "object": "number of requests"
  },
  {
    "subject": "memory",
    "predicate": "can be wasted by",
    "object": "fragmentation and redundant duplication"
  },
  {
    "subject": "wasted memory",
    "predicate": "limits",
    "object": "batch size"
  },
  {
    "subject": "Inefficient memory management",
    "predicate": "can decrease",
    "object": "the batch size"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "is",
    "object": "an attention algorithm"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "is inspired by",
    "object": "the classical virtual memory and paging techniques in operating systems"
  },
  {
    "subject": "PAGEDAT-TENTION",
    "predicate": "is",
    "object": "an attention algorithm"
  },
  {
    "subject": "PAGEDAT-TENTION",
    "predicate": "is inspired by",
    "object": "the operating systems (OS) solution to memory fragmentation and sharing"
  },
  {
    "subject": "the operating systems (OS) solution to memory fragmentation and sharing",
    "predicate": "is",
    "object": "virtual memory with paging"
  },
  {
    "subject": "PagedAttention",
    "predicate": "operates on",
    "object": "KV cache stored in non-contiguous paged memory"
  },
  {
    "subject": "PagedAttention",
    "predicate": "is inspired by",
    "object": "the virtual memory and paging in OS"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "is introduced to address",
    "object": "the memory challenges in 3"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "is inspired by",
    "object": "the classic idea of paging in operating systems"
  },
  {
    "subject": "PagedAttention",
    "predicate": "allows storing",
    "object": "continuous keys and values in non-contiguous memory space"
  },
  {
    "subject": "attention key and values vectors",
    "predicate": "are stored as",
    "object": "non-contiguous blocks in the memory"
  },
  {
    "subject": "THIS PAPER",
    "predicate": "PROPOSES",
    "object": "PAGEDATTENTION"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "IS",
    "object": "A NEW ATTENTION ALGORITHM"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "ALLOWS",
    "object": "ATTENTION KEYS AND VALUES TO BE STORED IN NON-CONTIGUOUS PAGED MEMORY"
  },
  {
    "subject": "THIS PAPER",
    "predicate": "PRESENTS",
    "object": "VLLM"
  },
  {
    "subject": "VLLM",
    "predicate": "IS",
    "object": "A HIGH-THROUGHPUT LLM SERVING SYSTEM"
  },
  {
    "subject": "VLLM",
    "predicate": "HAS",
    "object": "EFFICIENT MEMORY MANAGEMENT ENABLED BY PAGEDATTENTION"
  },
  {
    "subject": "VLLM",
    "predicate": "is",
    "object": "an LLM serving system"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "near-zero waste in KV cache memory"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "flexible sharing of KV cache within and across requests"
  },
  {
    "subject": "flexible sharing of KV cache",
    "predicate": "purpose",
    "object": "to further reduce memory usage"
  },
  {
    "subject": "existing LLM serving systems 31, 60",
    "predicate": "fall short of managing",
    "object": "the KV cache memory efficiently"
  },
  {
    "subject": "we",
    "predicate": "can manage",
    "object": "the KV cache in a more flexible way as in OSS virtual memory"
  },
  {
    "subject": "blocks",
    "predicate": "are",
    "object": "pages"
  },
  {
    "subject": "tokens",
    "predicate": "are",
    "object": "bytes"
  },
  {
    "subject": "requests",
    "predicate": "are",
    "object": "processes"
  },
  {
    "subject": "established techniques",
    "predicate": "are inspired by",
    "object": "operating systems"
  },
  {
    "subject": "established techniques",
    "predicate": "include",
    "object": "virtual memory"
  },
  {
    "subject": "established techniques",
    "predicate": "include",
    "object": "copy-on-write"
  },
  {
    "subject": "established techniques such as virtual memory and copy-on-write",
    "predicate": "can be adapted to",
    "object": "efficiently manage KV cache"
  },
  {
    "subject": "established techniques such as virtual memory and copy-on-write",
    "predicate": "can be adapted to",
    "object": "handle various decoding algorithms in LLM serving"
  },
  {
    "subject": "VLLM",
    "predicate": "improves",
    "object": "LLM serving throughput by 2-4 compared to the state-of-the-art systems 31, 60"
  },
  {
    "subject": "VLLM",
    "predicate": "does not affect",
    "object": "model accuracy"
  },
  {
    "subject": "WE",
    "predicate": "evaluate",
    "object": "the performance of VLLM under a variety of workloads"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "2-4 throughput improvements over the state-of-the-art systems"
  },
  {
    "subject": "The improvement",
    "predicate": "is more pronounced with",
    "object": "longer sequences"
  },
  {
    "subject": "The improvement",
    "predicate": "is more pronounced with",
    "object": "larger models"
  },
  {
    "subject": "The improvement",
    "predicate": "is more pronounced with",
    "object": "more complex decoding algorithms"
  },
  {
    "subject": "improvements",
    "predicate": "are more pronounced with",
    "object": "longer sequences"
  },
  {
    "subject": "improvements",
    "predicate": "are more pronounced with",
    "object": "larger models"
  },
  {
    "subject": "improvements",
    "predicate": "are more pronounced with",
    "object": "more complex decoding algorithms"
  },
  {
    "subject": "VLLMS source code",
    "predicate": "is publicly available at",
    "object": "https://github.com/vllm-project/vllm"
  },
  {
    "subject": "Many cloud companies 34, 44",
    "predicate": "are racing to provide",
    "object": "these applications as hosted services"
  },
  {
    "subject": "running these applications",
    "predicate": "is",
    "object": "very expensive"
  },
  {
    "subject": "running these applications",
    "predicate": "requires",
    "object": "a large number of hardware accelerators such as GPUs"
  },
  {
    "subject": "processing an LLM request",
    "predicate": "can be",
    "object": "10 more expensive than a traditional keyword query"
  },
  {
    "subject": "SOSP 23",
    "predicate": "date",
    "object": "OCTOBER 23-26, 2023"
  },
  {
    "subject": "SOSP 23",
    "predicate": "location",
    "object": "Koblenz, Germany"
  },
  {
    "subject": "Copyright",
    "predicate": "held by",
    "object": "the owner author(s)"
  },
  {
    "subject": "Copyright",
    "predicate": "year",
    "object": "2023"
  },
  {
    "subject": "ACM",
    "predicate": "has ISBN",
    "object": "979-8-4007-0229-72310"
  },
  {
    "subject": "NVIDIA A100",
    "predicate": "has memory size",
    "object": "40GB"
  },
  {
    "subject": "KV cache",
    "predicate": "size",
    "object": "26GB"
  },
  {
    "subject": "KV cache",
    "predicate": "parameter",
    "object": "65"
  },
  {
    "subject": "Others",
    "predicate": "parameter",
    "object": "20"
  },
  {
    "subject": "Others",
    "predicate": "parameter",
    "object": "30"
  },
  {
    "subject": "Others",
    "predicate": "parameter",
    "object": "40"
  },
  {
    "subject": "Memory usage",
    "predicate": "unit",
    "object": "GB"
  },
  {
    "subject": "Batch size",
    "predicate": "unit",
    "object": "requests"
  },
  {
    "subject": "Throughput",
    "predicate": "unit",
    "object": "tokens"
  },
  {
    "subject": "LLM",
    "predicate": "has",
    "object": "13B parameters"
  },
  {
    "subject": "LLM with 13B parameters",
    "predicate": "is served on",
    "object": "NVIDIA A100"
  },
  {
    "subject": "memory distribution",
    "predicate": "is illustrated for",
    "object": "a 13B-parameter LLM on an NVIDIA A100 GPU with 40GB RAM"
  },
  {
    "subject": "THE PARAMETERS (GRAY)",
    "predicate": "persist in",
    "object": "GPU MEMORY throughout serving"
  },
  {
    "subject": "the contiguous chunk of memory",
    "predicate": "is used to store",
    "object": "the KV cache of a request"
  },
  {
    "subject": "all available memory",
    "predicate": "was allocated to",
    "object": "KV cache"
  },
  {
    "subject": "only a few tens of requests",
    "predicate": "could be accommodated",
    "object": ""
  },
  {
    "subject": "output length of a request",
    "predicate": "grows at",
    "object": "decoding"
  },
  {
    "subject": "memory required for its KV cache",
    "predicate": "expands",
    "object": "as output length of a request grows at decoding"
  },
  {
    "subject": "memory required for its KV cache",
    "predicate": "may exhaust",
    "object": "available memory for incoming requests or ongoing generation for existing prompts"
  },
  {
    "subject": "A small amount of memory (yellow)",
    "predicate": "is used",
    "object": "ephemerally for activation"
  },
  {
    "subject": "VLLM",
    "predicate": "smooths out",
    "object": "the rapid growth curve of KV cache memory seen in existing systems 31, 60"
  },
  {
    "subject": "smoothing out the rapid growth curve of KV cache memory",
    "predicate": "leads to",
    "object": "a notable boost in serving throughput"
  },
  {
    "subject": "The key idea behind VLLMS memory manager",
    "predicate": "is analogous to",
    "object": "the virtual memory in operating systems"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "the ideas behind virtual memory"
  },
  {
    "subject": "the ideas behind virtual memory",
    "predicate": "to manage",
    "object": "the KV cache in an LLM service"
  },
  {
    "subject": "cost per request of LLM serving systems",
    "predicate": "is becoming",
    "object": "more important"
  },
  {
    "subject": "LLMs",
    "predicate": "have at their core",
    "object": "an autoregressive transformer model"
  },
  {
    "subject": "this model",
    "predicate": "generates",
    "object": "words (tokens)"
  },
  {
    "subject": "this model",
    "predicate": "generates words one at a time",
    "object": null
  },
  {
    "subject": "this model",
    "predicate": "generates words based on",
    "object": "the input (prompt)"
  },
  {
    "subject": "this model",
    "predicate": "generates words based on",
    "object": "the previous sequence of the output tokens it has generated so far"
  },
  {
    "subject": "this expensive process",
    "predicate": "is repeated",
    "object": "for each request"
  },
  {
    "subject": "this expensive process",
    "predicate": "is repeated",
    "object": "until the model outputs a termination token"
  },
  {
    "subject": "This sequential generation process",
    "predicate": "makes",
    "object": "the workload memory-bound"
  },
  {
    "subject": "This sequential generation process",
    "predicate": "underutilizes",
    "object": "the computation power of GPUs"
  },
  {
    "subject": "This sequential generation process",
    "predicate": "limits",
    "object": "the serving throughput"
  },
  {
    "subject": "improving the throughput",
    "predicate": "is possible by",
    "object": "batching multiple requests together"
  },
  {
    "subject": "memory space for each request",
    "predicate": "should be",
    "object": "efficiently managed"
  },
  {
    "subject": "approximately 65 of the memory",
    "predicate": "is allocated for",
    "object": "the model weights"
  },
  {
    "subject": "the model weights",
    "predicate": "remain",
    "object": "static during serving"
  },
  {
    "subject": "close to 30 of the memory",
    "predicate": "is used to store",
    "object": "the dynamic states of the requests"
  },
  {
    "subject": "these states",
    "predicate": "consist of",
    "object": "the key and value tensors associated with the attention mechanism"
  },
  {
    "subject": "the key and value tensors",
    "predicate": "are referred to as",
    "object": "KV cache 41"
  },
  {
    "subject": "KV cache 41",
    "predicate": "represent",
    "object": "the context from earlier tokens"
  },
  {
    "subject": "KV cache 41",
    "predicate": "generate",
    "object": "new output tokens in sequence"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "KV CACHE USAGE",
    "object": "20.4"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "KV CACHE USAGE",
    "object": "13.3"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "KV CACHE USAGE",
    "object": "57.3"
  },
  {
    "subject": "VLLM",
    "predicate": "KV CACHE USAGE",
    "object": "8.9"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "TOKEN STATES RESERVATION",
    "object": "26.8"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "TOKEN STATES RESERVATION",
    "object": "17.9"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "TOKEN STATES RESERVATION",
    "object": "13.6"
  },
  {
    "subject": "VLLM",
    "predicate": "TOKEN STATES RESERVATION",
    "object": "41.6"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "INTERNAL FRAG.",
    "object": "38.2"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "INTERNAL FRAG.",
    "object": "25.2"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "INTERNAL FRAG.",
    "object": "36.6"
  },
  {
    "subject": "VLLM",
    "predicate": "INTERNAL FRAG.",
    "object": "96.3"
  },
  {
    "subject": "We",
    "predicate": "identify",
    "object": "the challenges in memory allocation in serving LLMs"
  },
  {
    "subject": "We",
    "predicate": "quantify",
    "object": "their impact on serving performance"
  },
  {
    "subject": "Percentage of memory",
    "predicate": "is used for",
    "object": "other data, including activations"
  },
  {
    "subject": "Ephemeral tensors",
    "predicate": "are created when",
    "object": "evaluating the LLM"
  },
  {
    "subject": "model weights",
    "predicate": "are",
    "object": "constant"
  },
  {
    "subject": "activations",
    "predicate": "occupy",
    "object": "a small fraction of the GPU memory"
  },
  {
    "subject": "the way the KV cache is managed",
    "predicate": "is",
    "object": "critical in determining the maximum batch size"
  },
  {
    "subject": "KV cache memory",
    "predicate": "can limit",
    "object": "batch size"
  },
  {
    "subject": "KV cache memory",
    "predicate": "can limit",
    "object": "throughput of the LLM"
  },
  {
    "subject": "inefficient management",
    "predicate": "causes",
    "object": "KV cache memory to limit batch size and throughput"
  },
  {
    "subject": "fine-grained batching",
    "predicate": "reduces",
    "object": "the waste of computing"
  },
  {
    "subject": "fine-grained batching",
    "predicate": "enables",
    "object": "requests to be batched in a more flexible way"
  },
  {
    "subject": "the number of requests that can be batched together",
    "predicate": "is constrained by",
    "object": "GPU memory capacity"
  },
  {
    "subject": "GPU memory capacity",
    "predicate": "particularly constrains",
    "object": "the space allocated to store the KV cache"
  },
  {
    "subject": "The idea of virtual memory and paging",
    "predicate": "is effective for",
    "object": "managing the KV cache in LLM serving"
  },
  {
    "subject": "The workload",
    "predicate": "requires",
    "object": "dynamic memory allocation"
  },
  {
    "subject": "The output length",
    "predicate": "is",
    "object": "not known a priori"
  },
  {
    "subject": "Its performance",
    "predicate": "is bound by",
    "object": "the GPU memory capacity"
  },
  {
    "subject": "Most deep learning frameworks 33, 39",
    "predicate": "require",
    "object": "tensors to be stored in contiguous memory"
  },
  {
    "subject": "most operators in current deep learning frameworks 33, 39",
    "predicate": "require",
    "object": "tensors to be stored in contiguous memory"
  },
  {
    "subject": "previous LLM serving systems 31, 60",
    "predicate": "store",
    "object": "the KV cache of one request as a contiguous tensor across the different positions"
  },
  {
    "subject": "KV cache",
    "predicate": "has",
    "object": "unique characteristics"
  },
  {
    "subject": "KV cache",
    "predicate": "dynamically grows and shrinks",
    "object": "over time"
  },
  {
    "subject": "KV cache",
    "predicate": "grows and shrinks",
    "object": "as the model generates new tokens"
  },
  {
    "subject": "lifetime and length of KV cache",
    "predicate": "are",
    "object": "not known a priori"
  },
  {
    "subject": "tensors in traditional deep learning workloads",
    "predicate": "are",
    "object": "unlike KV cache"
  },
  {
    "subject": "existing systems",
    "predicate": "are",
    "object": "significantly inefficient"
  },
  {
    "subject": "existing systems",
    "predicate": "suffer from",
    "object": "internal memory fragmentation"
  },
  {
    "subject": "existing systems",
    "predicate": "suffer from",
    "object": "external memory fragmentation"
  },
  {
    "subject": "requests actual length",
    "predicate": "can be",
    "object": "much shorter than its maximum length"
  },
  {
    "subject": "the pre-allocation",
    "predicate": "is",
    "object": "inefficient"
  },
  {
    "subject": "the entire chunk",
    "predicate": "is reserved during",
    "object": "the requests lifetime"
  },
  {
    "subject": "other shorter requests",
    "predicate": "cannot utilize",
    "object": "any part of the chunk that is currently unused"
  },
  {
    "subject": "External memory fragmentation",
    "predicate": "can be",
    "object": "significant"
  },
  {
    "subject": "Pre-allocated size",
    "predicate": "can be different for",
    "object": "each request"
  },
  {
    "subject": "KV cache memory",
    "predicate": "is used to store",
    "object": "the actual token states"
  },
  {
    "subject": "the actual token states",
    "predicate": "are stored in",
    "object": "the existing systems"
  },
  {
    "subject": "percentage of KV cache memory used",
    "predicate": "is",
    "object": "20.4 - 38.2%"
  },
  {
    "subject": "KV cache of one token",
    "predicate": "depends on",
    "object": "all its previous tokens"
  },
  {
    "subject": "KV cache of the same token appearing at different positions in a sequence",
    "predicate": "will be",
    "object": "different"
  },
  {
    "subject": "THE TOKEN IN EACH MEMORY SLOT",
    "predicate": "represents",
    "object": "ITS KV CACHE"
  },
  {
    "subject": "the same tokens",
    "predicate": "can have",
    "object": "different KV cache"
  },
  {
    "subject": "different KV cache",
    "predicate": "occur",
    "object": "at different positions"
  },
  {
    "subject": "existing systems",
    "predicate": "cannot exploit",
    "object": "opportunities for memory sharing"
  },
  {
    "subject": "LLM services",
    "predicate": "use",
    "object": "advanced decoding algorithms"
  },
  {
    "subject": "advanced decoding algorithms",
    "predicate": "include",
    "object": "parallel sampling"
  },
  {
    "subject": "advanced decoding algorithms",
    "predicate": "include",
    "object": "beam search"
  },
  {
    "subject": "advanced decoding algorithms",
    "predicate": "generate",
    "object": "multiple outputs per request"
  },
  {
    "subject": "LLM services",
    "predicate": "offer",
    "object": "a range of decoding algorithms"
  },
  {
    "subject": "decoding algorithms",
    "predicate": "are for",
    "object": "users to select from"
  },
  {
    "subject": "decoding algorithms",
    "predicate": "have",
    "object": "varying implications for memory management complexity"
  },
  {
    "subject": "an LLM service",
    "predicate": "must offer",
    "object": "more complex decoding scenarios"
  },
  {
    "subject": "more complex decoding scenarios",
    "predicate": "exhibit",
    "object": "complex accessing patterns"
  },
  {
    "subject": "an LLM service",
    "predicate": "must offer",
    "object": "more opportunities for memory sharing"
  },
  {
    "subject": "the request",
    "predicate": "consists of",
    "object": "multiple sequences"
  },
  {
    "subject": "multiple sequences",
    "predicate": "can partially share",
    "object": "their KV cache"
  },
  {
    "subject": "KV cache",
    "predicate": "is stored",
    "object": "of two requests at the same time in vLLM"
  },
  {
    "subject": "a request",
    "predicate": "finishes",
    "object": "its generation"
  },
  {
    "subject": "its KV blocks",
    "predicate": "can be freed",
    "object": "to store the KV cache of other requests"
  },
  {
    "subject": "memory sharing",
    "predicate": "is not possible in",
    "object": "the existing systems"
  },
  {
    "subject": "the KV cache of the sequences",
    "predicate": "is stored in",
    "object": "separate contiguous spaces"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "divides",
    "object": "the requests KV cache into blocks"
  },
  {
    "subject": "each block",
    "predicate": "can contain",
    "object": "the attention keys and values of a fixed number of tokens"
  },
  {
    "subject": "PAGEDATTENTION KERNEL",
    "predicate": "identifies and fetches",
    "object": "different KV blocks separately"
  },
  {
    "subject": "blocks for the KV cache",
    "predicate": "are not necessarily stored in",
    "object": "contiguous space"
  },
  {
    "subject": "THE KV CACHE MANAGER",
    "predicate": "manages",
    "object": "THE KV CACHE"
  },
  {
    "subject": "THE KV CACHE MANAGER",
    "predicate": "manages in",
    "object": "A PAGED FASHION"
  },
  {
    "subject": "A PAGED FASHION",
    "predicate": "is enabled by",
    "object": "PAGEDATTENTION"
  },
  {
    "subject": "We",
    "predicate": "show",
    "object": "the design of the KV cache manager in 4.2"
  },
  {
    "subject": "the design of the KV cache manager",
    "predicate": "facilitates",
    "object": "paged attention in 4.3"
  },
  {
    "subject": "PAGEDATTENTION",
    "predicate": "partitions",
    "object": "the KV cache of each sequence into KV blocks"
  },
  {
    "subject": "WE",
    "predicate": "organize",
    "object": "the KV cache as fixed-size KV blocks"
  },
  {
    "subject": "fixed-size KV blocks",
    "predicate": "are like",
    "object": "pages in virtual memory"
  },
  {
    "subject": "PagedAttention",
    "predicate": "enables",
    "object": "organizing the KV cache as fixed-size KV blocks"
  },
  {
    "subject": "THIS DESIGN",
    "predicate": "alleviates",
    "object": "internal fragmentation"
  },
  {
    "subject": "THIS DESIGN",
    "predicate": "uses",
    "object": "relatively small blocks"
  },
  {
    "subject": "THIS DESIGN",
    "predicate": "allocates",
    "object": "them on demand"
  },
  {
    "subject": "All blocks",
    "predicate": "have",
    "object": "the same size"
  },
  {
    "subject": "memory sharing",
    "predicate": "occurs across",
    "object": "the different sequences associated with the same request"
  },
  {
    "subject": "memory sharing",
    "predicate": "occurs across",
    "object": "the different requests"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "block-level memory management"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "preemptive request scheduling"
  },
  {
    "subject": "block-level memory management and preemptive request scheduling",
    "predicate": "are co-designed with",
    "object": "PagedAttention"
  },
  {
    "subject": "PagedAttention algorithm",
    "predicate": "allows",
    "object": "the KV blocks to be stored in non-contiguous physical memory"
  },
  {
    "subject": "Storing KV blocks in non-contiguous physical memory",
    "predicate": "enables",
    "object": "more flexible paged memory management in VLLM"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "the PagedAttention kernel to access the previous KV cache stored in the form of logical KV blocks"
  },
  {
    "subject": "VLLM",
    "predicate": "saves",
    "object": "the newly generated KV cache into the physical KV blocks"
  },
  {
    "subject": "VLLM",
    "predicate": "can realize",
    "object": "this sharing easily"
  },
  {
    "subject": "VLLM",
    "predicate": "can save",
    "object": "memory"
  },
  {
    "subject": "this sharing",
    "predicate": "is via",
    "object": "its PagedAttention and Paged Memory Management"
  },
  {
    "subject": "VLLM",
    "predicate": "supports",
    "object": "popular LLMs such as GPT 5, OPT 62, and LLAMA 52"
  },
  {
    "subject": "popular LLMs such as GPT 5, OPT 62, and LLAMA 52",
    "predicate": "have",
    "object": "varying sizes"
  },
  {
    "subject": "varying sizes",
    "predicate": "include",
    "object": "ones exceeding the memory capacity of a single GPU"
  },
  {
    "subject": "VLLM",
    "predicate": "is",
    "object": "a distributed LLM serving engine"
  },
  {
    "subject": "VLLM",
    "predicate": "is built on top of",
    "object": "PagedAttention"
  },
  {
    "subject": "We",
    "predicate": "evaluate",
    "object": "VLLM on various scenarios"
  },
  {
    "subject": "VLLM",
    "predicate": "outperforms",
    "object": "previous state-of-the-art solutions such as FasterTransformer 31 and Orca 60"
  },
  {
    "subject": "VLLM",
    "predicate": "can sustain",
    "object": "up to 22 higher request rates compared to FasterTransformer"
  },
  {
    "subject": "FasterTransformer",
    "predicate": "does not utilize",
    "object": "a fine-grained scheduling mechanism"
  },
  {
    "subject": "FasterTransformer",
    "predicate": "manages memory",
    "object": "inefficiently like ORCA (MAX)"
  },
  {
    "subject": "VLLM",
    "predicate": "reduces",
    "object": "memory fragmentation"
  },
  {
    "subject": "VLLM",
    "predicate": "enables",
    "object": "sharing"
  },
  {
    "subject": "VLLM",
    "predicate": "runs",
    "object": "more requests in a batch in parallel"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "a 2-4 speedup compared to ORCA"
  },
  {
    "subject": "this section",
    "predicate": "describes",
    "object": "the generation and serving procedures of typical LLMs"
  },
  {
    "subject": "this section",
    "predicate": "describes",
    "object": "the iteration-level scheduling used in LLM serving"
  },
  {
    "subject": "The task of language modeling",
    "predicate": "is to model",
    "object": "the probability of a list of tokens"
  },
  {
    "subject": "language",
    "predicate": "has",
    "object": "a natural sequential ordering"
  },
  {
    "subject": "TRANSFORMERS 53",
    "predicate": "have become",
    "object": "the de facto standard architecture for modeling the probability above at a large scale"
  },
  {
    "subject": "the most important component of a transformer-based language model",
    "predicate": "is",
    "object": "its self-attention layers"
  },
  {
    "subject": "A self-attention layer",
    "predicate": "applies",
    "object": "linear transformations on each position to get the query, key, and value vectors"
  },
  {
    "subject": "self-attention layer",
    "predicate": "computes",
    "object": "attention score"
  },
  {
    "subject": "attention score",
    "predicate": "is computed by",
    "object": "multiplying the query vector at one position with all the key vectors before it"
  },
  {
    "subject": "self-attention layer",
    "predicate": "computes",
    "object": "output as the weighted average over the value vectors"
  },
  {
    "subject": "all other components",
    "predicate": "are in",
    "object": "the transformer model"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "the embedding layer"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "feed-forward layer"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "layer normalization 2"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "residual connection 22"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "output logit computation"
  },
  {
    "subject": "all other components",
    "predicate": "include",
    "object": "the query, key, and value transformation in eq"
  },
  {
    "subject": "LLMs",
    "predicate": "are deployed as",
    "object": "a conditional generation service"
  },
  {
    "subject": "A REQUEST TO AN LLM SERVICE",
    "predicate": "PROVIDES",
    "object": "A LIST OF INPUT PROMPT TOKENS"
  },
  {
    "subject": "the concatenation of the prompt and output lists",
    "predicate": "is referred to as",
    "object": "sequence"
  },
  {
    "subject": "THE LLM",
    "predicate": "can only sample and generate",
    "object": "new tokens one by one"
  },
  {
    "subject": "The generation process of each new token",
    "predicate": "depends on",
    "object": "all the previous tokens in that sequence"
  },
  {
    "subject": "All the previous tokens in that sequence",
    "predicate": "have",
    "object": "key and value vectors"
  },
  {
    "subject": "key and value vectors of existing tokens",
    "predicate": "are often cached",
    "object": "for generating future tokens"
  },
  {
    "subject": "generating future tokens",
    "predicate": "is known as",
    "object": "KV cache"
  },
  {
    "subject": "A requests KV cache",
    "predicate": "is represented as",
    "object": "a series of logical KV blocks"
  },
  {
    "subject": "logical KV blocks",
    "predicate": "are filled from",
    "object": "left to right"
  },
  {
    "subject": "logical KV blocks",
    "predicate": "are filled as",
    "object": "new tokens and their KV cache are generated"
  },
  {
    "subject": "the generation computation in the LLM service",
    "predicate": "can be decomposed into",
    "object": "two phases"
  },
  {
    "subject": "the prompt phase",
    "predicate": "takes",
    "object": "the whole user prompt"
  },
  {
    "subject": "this process",
    "predicate": "generates",
    "object": "the key vectors 1"
  },
  {
    "subject": "the computation of the prompt phase",
    "predicate": "can be parallelized using",
    "object": "matrix-matrix multiplication operations"
  },
  {
    "subject": "this phase",
    "predicate": "can efficiently use",
    "object": "the parallelism inherent in GPUs"
  },
  {
    "subject": "THE AUTOREGRESSIVE GENERATION PHASE",
    "predicate": "GENERATES",
    "object": "THE REMAINING NEW TOKENS SEQUENTIALLY"
  },
  {
    "subject": "THE MODEL",
    "predicate": "takes as input",
    "object": "ONE TOKEN AT ITERATION"
  },
  {
    "subject": "key and value vectors at positions 1 to 1",
    "predicate": "are cached at",
    "object": "previous iterations"
  },
  {
    "subject": "new key and value vector",
    "predicate": "are computed at",
    "object": "this iteration"
  },
  {
    "subject": "this phase",
    "predicate": "completes when",
    "object": "the sequence reaches a maximum length"
  },
  {
    "subject": "maximum length",
    "predicate": "is specified by",
    "object": "users"
  },
  {
    "subject": "maximum length",
    "predicate": "is limited by",
    "object": "LLMs"
  },
  {
    "subject": "this phase",
    "predicate": "completes when",
    "object": "an end-of-sequence (EOS) token is emitted"
  },
  {
    "subject": "The computation at different iterations",
    "predicate": "cannot be parallelized",
    "object": "due to the data dependency"
  },
  {
    "subject": "The computation at different iterations",
    "predicate": "often uses",
    "object": "matrix-vector multiplication"
  },
  {
    "subject": "Matrix-vector multiplication",
    "predicate": "is",
    "object": "less efficient"
  },
  {
    "subject": "this phase",
    "predicate": "underutilizes",
    "object": "GPU computation"
  },
  {
    "subject": "this phase",
    "predicate": "becomes",
    "object": "memory-bound"
  },
  {
    "subject": "this phase",
    "predicate": "is responsible for",
    "object": "most portion of the latency of a single request"
  },
  {
    "subject": "compute utilization in serving LLMs",
    "predicate": "can be improved by",
    "object": "batching multiple requests"
  },
  {
    "subject": "Batching the requests to an LLM service",
    "predicate": "is",
    "object": "non-trivial"
  },
  {
    "subject": "Batching the requests to an LLM service",
    "predicate": "is non-trivial for",
    "object": "two reasons"
  },
  {
    "subject": "the requests",
    "predicate": "share",
    "object": "the same model weights"
  },
  {
    "subject": "the overhead of moving weights",
    "predicate": "is amortized across",
    "object": "the requests in a batch"
  },
  {
    "subject": "the overhead of moving weights",
    "predicate": "can be overwhelmed by",
    "object": "the computational overhead"
  },
  {
    "subject": "the computational overhead",
    "predicate": "overwhelms the overhead of moving weights when",
    "object": "the batch size is sufficiently large"
  },
  {
    "subject": "requests",
    "predicate": "may arrive at",
    "object": "different times"
  },
  {
    "subject": "A naive batching strategy",
    "predicate": "would either make",
    "object": "earlier requests wait for later ones"
  },
  {
    "subject": "A naive batching strategy",
    "predicate": "would either delay",
    "object": "the incoming requests until earlier ones finish"
  },
  {
    "subject": "Delaying incoming requests until earlier ones finish",
    "predicate": "leads to",
    "object": "significant queueing delays"
  },
  {
    "subject": "requests",
    "predicate": "may have",
    "object": "vastly different input and output lengths"
  },
  {
    "subject": "A straightforward batching technique",
    "predicate": "would pad",
    "object": "the inputs and outputs of the requests"
  },
  {
    "subject": "Padding the inputs and outputs of the requests",
    "predicate": "to do what",
    "object": "equalize their lengths"
  },
  {
    "subject": "Padding the inputs and outputs of the requests",
    "predicate": "results in",
    "object": "wasting GPU computation and memory"
  },
  {
    "subject": "fine-grained batching mechanisms",
    "predicate": "have been proposed",
    "object": "to address this problem"
  },
  {
    "subject": "fine-grained batching mechanisms",
    "predicate": "include",
    "object": "cellular batching 16"
  },
  {
    "subject": "fine-grained batching mechanisms",
    "predicate": "include",
    "object": "iteration-level scheduling 60"
  },
  {
    "subject": "these techniques",
    "predicate": "operate at",
    "object": "the iteration level"
  },
  {
    "subject": "traditional methods",
    "predicate": "work at",
    "object": "the request level"
  },
  {
    "subject": "completed requests",
    "predicate": "are removed from",
    "object": "the batch"
  },
  {
    "subject": "new ones",
    "predicate": "are added",
    "object": "the batch"
  },
  {
    "subject": "a new request",
    "predicate": "can be processed after",
    "object": "waiting for a single iteration"
  },
  {
    "subject": "a new request",
    "predicate": "cannot be processed after",
    "object": "waiting for the entire batch to complete"
  },
  {
    "subject": "special GPU kernels",
    "predicate": "eliminate",
    "object": "the need to pad the inputs and outputs"
  },
  {
    "subject": "fine-grained batching mechanisms",
    "predicate": "increase",
    "object": "the throughput of LLM serving"
  },
  {
    "subject": "reducing the queueing delay and the inefficiencies from padding",
    "predicate": "causes",
    "object": "fine-grained batching mechanisms to increase the throughput of LLM serving"
  },
  {
    "subject": "Our fathers",
    "predicate": "brought forth",
    "object": "EOS RESV"
  },
  {
    "subject": "You",
    "predicate": "only live once",
    "object": ""
  },
  {
    "subject": "Slots",
    "predicate": "never used (internal fragmentation)",
    "object": "2038"
  },
  {
    "subject": "Slots",
    "predicate": "future used (reserved)",
    "object": "2"
  },
  {
    "subject": "External fragmentation",
    "predicate": "is",
    "object": ""
  },
  {
    "subject": "KV cache states for request AS prompt",
    "predicate": "are",
    "object": "7"
  },
  {
    "subject": "KV cache states for request BS prompt",
    "predicate": "are",
    "object": "3"
  },
  {
    "subject": "Slots",
    "predicate": "never used (internal fragmentation)",
    "object": "507"
  },
  {
    "subject": "Request B",
    "predicate": "is",
    "object": "current iteration"
  },
  {
    "subject": "Slot",
    "predicate": "is for",
    "object": "generated token"
  },
  {
    "subject": "Three types of memory wastes",
    "predicate": "are",
    "object": "reserved, internal fragmentation, and external fragmentation"
  },
  {
    "subject": "Reserved, internal fragmentation, and external fragmentation",
    "predicate": "exist",
    "object": "to prevent other requests from fitting into the memory"
  },
  {
    "subject": "THE SERVING SYSTEMS THROUGHPUT",
    "predicate": "is",
    "object": "MEMORY-BOUND"
  },
  {
    "subject": "the performance of the systems",
    "predicate": "becomes",
    "object": "compute-bound rather than memory-bound"
  },
  {
    "subject": "overcoming this memory-bound",
    "predicate": "requires addressing",
    "object": "the following challenges in the memory management: large KV cache"
  },
  {
    "subject": "KV cache of a single token",
    "predicate": "demands",
    "object": "800 KB of space"
  },
  {
    "subject": "800 KB of space",
    "predicate": "is calculated as",
    "object": "2 (key and value vectors) × 5120 (hidden state size) × 40 (number of layers) × 2 (bytes per FP16)"
  },
  {
    "subject": "model",
    "predicate": "is",
    "object": "13B parameter OPT model 62"
  },
  {
    "subject": "OPT",
    "predicate": "can generate sequences up to",
    "object": "2048 tokens"
  },
  {
    "subject": "the memory required to store the KV cache of one request",
    "predicate": "can be as much as",
    "object": "1.6 GB"
  },
  {
    "subject": "concurrent GPUs",
    "predicate": "have",
    "object": "memory capacities in the tens of GBs"
  },
  {
    "subject": "GPU's computation speed",
    "predicate": "grows faster than",
    "object": "memory capacity"
  },
  {
    "subject": "FLOPS",
    "predicate": "increases by",
    "object": "more than 2x from NVIDIA A100 to H100"
  },
  {
    "subject": "GPU memory",
    "predicate": "stays at",
    "object": "80GB maximum"
  },
  {
    "subject": "the memory",
    "predicate": "will become",
    "object": "an increasingly significant bottleneck"
  },
  {
    "subject": "users",
    "predicate": "request",
    "object": "multiple random samples from a single input prompt"
  },
  {
    "subject": "the KV cache of the prompt part",
    "predicate": "accounts for",
    "object": "12 of the total KV cache memory in our experiment (6.3)"
  },
  {
    "subject": "the KV cache of the prompt part",
    "predicate": "can be shared to",
    "object": "minimize memory usage"
  },
  {
    "subject": "KV cache",
    "predicate": "should remain",
    "object": "unshared during the autoregressive generation phase"
  },
  {
    "subject": "different sample results and their dependence on context and position",
    "predicate": "cause",
    "object": "KV cache to remain unshared"
  },
  {
    "subject": "The extent of KV cache sharing",
    "predicate": "depends on",
    "object": "the specific decoding algorithm employed"
  },
  {
    "subject": "different request beams",
    "predicate": "can share",
    "object": "larger portions (up to 55 memory saving) of their KV cache"
  },
  {
    "subject": "the sharing pattern",
    "predicate": "evolves",
    "object": "as the decoding process advances"
  },
  {
    "subject": "requests to an LLM service",
    "predicate": "exhibit",
    "object": "variability in their input and output lengths"
  },
  {
    "subject": "LLM services",
    "predicate": "face",
    "object": "a unique challenge"
  },
  {
    "subject": "input prompts for an LLM",
    "predicate": "can vary",
    "object": "significantly in length"
  },
  {
    "subject": "resulting output lengths",
    "predicate": "are not known",
    "object": "a priori"
  },
  {
    "subject": "resulting output lengths",
    "predicate": "are contingent on",
    "object": "both the input prompt and the model"
  },
  {
    "subject": "THE MEMORY MANAGEMENT SYSTEM",
    "predicate": "REQUIRES TO ACCOMMODATE",
    "object": "A WIDE RANGE OF PROMPT LENGTHS"
  },
  {
    "subject": "THE SYSTEM",
    "predicate": "needs to make",
    "object": "scheduling decisions"
  },
  {
    "subject": "scheduling decisions",
    "predicate": "include",
    "object": "deleting the KV cache of some requests from GPU memory"
  },
  {
    "subject": "scheduling decisions",
    "predicate": "include",
    "object": "swapping out the KV cache of some requests from GPU memory"
  },
  {
    "subject": "The allocation",
    "predicate": "is irrespective of",
    "object": "the actual input or eventual output length of the request"
  },
  {
    "subject": "Output lengths from the LLM",
    "predicate": "are",
    "object": "unpredictable"
  },
  {
    "subject": "3",
    "predicate": "illustrates",
    "object": "two requests"
  },
  {
    "subject": "Request A",
    "predicate": "has",
    "object": "2048 maximum possible sequence length"
  },
  {
    "subject": "Request B",
    "predicate": "has",
    "object": "maximum of 512"
  },
  {
    "subject": "THE CHUNK PRE-ALLOCATION SCHEME IN EXISTING SYSTEMS",
    "predicate": "has",
    "object": "three primary sources of memory wastes"
  },
  {
    "subject": "three primary sources of memory wastes",
    "predicate": "include",
    "object": "reserved slots for future tokens"
  },
  {
    "subject": "three primary sources of memory wastes",
    "predicate": "include",
    "object": "internal fragmentation due to over-provisioning for potential maximum sequence lengths"
  },
  {
    "subject": "three primary sources of memory wastes",
    "predicate": "include",
    "object": "external fragmentation from the memory allocator like the buddy allocator"
  },
  {
    "subject": "THE EXTERNAL FRAGMENTATION",
    "predicate": "will never be used for",
    "object": "GENERATED TOKENS"
  },
  {
    "subject": "THE EXTERNAL FRAGMENTATION",
    "predicate": "is known",
    "object": "before serving a request"
  },
  {
    "subject": "Internal fragmentation",
    "predicate": "remains",
    "object": "unused"
  },
  {
    "subject": "reserving this space for the entire requests duration",
    "predicate": "occupies",
    "object": "the space that could otherwise be used to process other requests"
  },
  {
    "subject": "the reserved memory",
    "predicate": "is eventually used",
    "object": ""
  },
  {
    "subject": "we",
    "predicate": "visualize",
    "object": "the average percentage of memory wastes in our experiments in Fig."
  },
  {
    "subject": "the actual effective memory in previous systems",
    "predicate": "can be as low as",
    "object": "20.4"
  },
  {
    "subject": "614 KV CACHE MANAGER",
    "predicate": "includes",
    "object": "SCHEDULER"
  },
  {
    "subject": "614 KV CACHE MANAGER",
    "predicate": "includes",
    "object": "CPU BLOCK ALLOCATOR"
  },
  {
    "subject": "614 KV CACHE MANAGER",
    "predicate": "includes",
    "object": "GPU BLOCK ALLOCATOR"
  },
  {
    "subject": "614 KV CACHE MANAGER",
    "predicate": "includes",
    "object": "BLOCK TABLES"
  },
  {
    "subject": "614 KV CACHE MANAGER",
    "predicate": "includes",
    "object": "WORKER 0 MODEL SHARD 0 CACHE ENGINE"
  },
  {
    "subject": "The architecture of VLLM",
    "predicate": "is shown in",
    "object": "Fig."
  },
  {
    "subject": "the system design of VLLM",
    "predicate": "works in",
    "object": "a distributed setting"
  },
  {
    "subject": "Compaction 54",
    "predicate": "has been proposed as",
    "object": "a potential solution to fragmentation"
  },
  {
    "subject": "Performing compaction in a performance-sensitive LLM serving system",
    "predicate": "is",
    "object": "impractical"
  },
  {
    "subject": "Performing compaction in a performance-sensitive LLM serving system",
    "predicate": "is impractical due to",
    "object": "the massive KV cache"
  },
  {
    "subject": "the pre-allocated chunk space for each request",
    "predicate": "prevents",
    "object": "memory sharing specific to decoding algorithms in existing memory management systems"
  },
  {
    "subject": "we",
    "predicate": "develop",
    "object": "a new attention algorithm, Page-DAttention"
  },
  {
    "subject": "we",
    "predicate": "build",
    "object": "an LLM serving engine, VLLM"
  },
  {
    "subject": "VLLM",
    "predicate": "tackle",
    "object": "the challenges outlined in 3"
  },
  {
    "subject": "VLLM",
    "predicate": "adopts",
    "object": "a centralized scheduler"
  },
  {
    "subject": "a centralized scheduler",
    "predicate": "coordinates",
    "object": "the execution of distributed GPU workers"
  },
  {
    "subject": "KV cache manager",
    "predicate": "manages",
    "object": "the physical KV cache memory on the GPU workers"
  },
  {
    "subject": "KV cache manager",
    "predicate": "manages through",
    "object": "the instructions sent by the centralized scheduler"
  },
  {
    "subject": "each GPU worker",
    "predicate": "has",
    "object": "the same physical block IDs"
  },
  {
    "subject": "a worker",
    "predicate": "stores",
    "object": "a portion of the KV cache for its corresponding attention heads"
  },
  {
    "subject": "GPU workers",
    "predicate": "read",
    "object": "KV cache"
  },
  {
    "subject": "GPU workers",
    "predicate": "read according to",
    "object": "block table in the control message"
  },
  {
    "subject": "block table",
    "predicate": "is in",
    "object": "control message"
  },
  {
    "subject": "reading",
    "predicate": "occurs in",
    "object": "attention layers"
  },
  {
    "subject": "We",
    "predicate": "describe",
    "object": "the PagedAttention algorithm in 4.1"
  },
  {
    "subject": "WE",
    "predicate": "show",
    "object": "an example of PAGEDATTENTION in FIG."
  },
  {
    "subject": "this design",
    "predicate": "facilitates",
    "object": "effective memory management for various decoding methods (4.4)"
  },
  {
    "subject": "this design",
    "predicate": "handles",
    "object": "the variable length input and output sequences (4.5)"
  },
  {
    "subject": "each block",
    "predicate": "contains",
    "object": "the key and value vectors for a fixed number of tokens"
  },
  {
    "subject": "we",
    "predicate": "denote",
    "object": "each block as KV 1"
  },
  {
    "subject": "each token",
    "predicate": "has",
    "object": "a set of key and value vectors across layers and attention heads within a layer"
  },
  {
    "subject": "all the key and value vectors",
    "predicate": "can be managed",
    "object": "together within a single KV block"
  },
  {
    "subject": "the key and value vectors at different heads and layers",
    "predicate": "can each have",
    "object": "a separate block"
  },
  {
    "subject": "the key and value vectors at different heads and layers",
    "predicate": "can be managed",
    "object": "in separate block tables"
  },
  {
    "subject": "THE TWO DESIGNS",
    "predicate": "have",
    "object": "no performance difference"
  },
  {
    "subject": "WE",
    "predicate": "choose",
    "object": "the second one"
  },
  {
    "subject": "the second one",
    "predicate": "is chosen for",
    "object": "easy implementation"
  },
  {
    "subject": "our fathers",
    "predicate": "brought forth",
    "object": "four score and seven key and value vectors"
  },
  {
    "subject": "We",
    "predicate": "study",
    "object": "the effect of block size in 7.2"
  },
  {
    "subject": "4",
    "predicate": "can be transformed into",
    "object": "the following block-wise computation"
  },
  {
    "subject": "IS",
    "predicate": "the row vector of",
    "object": "ATTENTION SCORE on -TH KV BLOCK"
  },
  {
    "subject": "THE KEY AND VALUE VECTORS",
    "predicate": "are spread across",
    "object": "THREE BLOCKS"
  },
  {
    "subject": "THE THREE BLOCKS",
    "predicate": "are not contiguous on",
    "object": "THE PHYSICAL MEMORY"
  },
  {
    "subject": "the kernel",
    "predicate": "multiplies",
    "object": "the query vector of the query token (forth) and the key vectors in a block"
  },
  {
    "subject": "the kernel",
    "predicate": "computes",
    "object": "the attention score"
  },
  {
    "subject": "the kernel",
    "predicate": "multiplies with",
    "object": "the value vectors in a block"
  },
  {
    "subject": "the kernel",
    "predicate": "derives",
    "object": "the final attention output"
  },
  {
    "subject": "OS",
    "predicate": "partitions",
    "object": "memory into fixed-sized pages"
  },
  {
    "subject": "OS",
    "predicate": "maps",
    "object": "user programs logical pages to physical pages"
  },
  {
    "subject": "CONTIGUOUS LOGICAL PAGES",
    "predicate": "can correspond to",
    "object": "NON-CONTIGUOUS PHYSICAL MEMORY PAGES"
  },
  {
    "subject": "USER PROGRAMS",
    "predicate": "can access",
    "object": "MEMORY as though it were CONTIGUOUS"
  },
  {
    "subject": "physical memory space",
    "predicate": "needs not to be fully reserved",
    "object": "in advance"
  },
  {
    "subject": "the OS",
    "predicate": "enables",
    "object": "to dynamically allocate physical pages as needed"
  },
  {
    "subject": "THE LAST KV BLOCKS UNFILLED POSITIONS",
    "predicate": "ARE RESERVED FOR",
    "object": "FUTURE GENERATIONS"
  },
  {
    "subject": "A block engine",
    "predicate": "allocates",
    "object": "a contiguous chunk of GPU DRAM"
  },
  {
    "subject": "GPU workers",
    "predicate": "have",
    "object": "a block engine"
  },
  {
    "subject": "Fathers",
    "predicate": "brought",
    "object": "four score and seven years ago"
  },
  {
    "subject": "Physical KV blocks",
    "predicate": "are on",
    "object": "GPU DRAM"
  },
  {
    "subject": "Physical KV blocks",
    "predicate": "include",
    "object": "Block 0, Block 1, Block 2, Block 3, Block 4, Block 5, Block 6, Block 7, Block 8"
  },
  {
    "subject": "Logical KV blocks",
    "predicate": "are represented by",
    "object": "Physical block number"
  },
  {
    "subject": "BLOCK TABLE",
    "predicate": "is used in",
    "object": "TRANSLATION IN VLLM"
  },
  {
    "subject": "The KV block manager",
    "predicate": "maintains",
    "object": "block tables"
  },
  {
    "subject": "The KV block manager",
    "predicate": "maintains",
    "object": "the mapping between logical and physical KV blocks of each request"
  },
  {
    "subject": "each block table entry",
    "predicate": "records",
    "object": "the corresponding physical blocks of a logical block"
  },
  {
    "subject": "each block table entry",
    "predicate": "records",
    "object": "the number of filled positions"
  },
  {
    "subject": "Separating logical and physical KV blocks",
    "predicate": "allows",
    "object": "VLLM to dynamically grow the KV cache memory without reserving it for all positions in advance"
  },
  {
    "subject": "Separating logical and physical KV blocks",
    "predicate": "eliminates",
    "object": "most memory waste in existing systems"
  },
  {
    "subject": "all the blocks",
    "predicate": "are filled from",
    "object": "left to right"
  },
  {
    "subject": "a new physical block",
    "predicate": "is only allocated when",
    "object": "all previous blocks are full"
  },
  {
    "subject": "VLLM",
    "predicate": "limits",
    "object": "all the memory wastes for a request within one block"
  },
  {
    "subject": "VLLM",
    "predicate": "can effectively utilize",
    "object": "all the memory"
  },
  {
    "subject": "VLLM",
    "predicate": "enables",
    "object": "the sharing of most of the space used to store the prompts KV cache across multiple output samples"
  },
  {
    "subject": "the final logical block",
    "predicate": "is managed by",
    "object": "a copy-on-write mechanism"
  },
  {
    "subject": "VLLMS physical block sharing",
    "predicate": "reduces",
    "object": "frequent memory copy overhead"
  },
  {
    "subject": "VLLM",
    "predicate": "conceals",
    "object": "the complex memory sharing between different sequences"
  },
  {
    "subject": "the complex memory sharing",
    "predicate": "is via",
    "object": "a common mapping layer"
  },
  {
    "subject": "a common mapping layer",
    "predicate": "translates",
    "object": "logical blocks to physical blocks"
  },
  {
    "subject": "introducing the VLLMS techniques",
    "predicate": "may degrade",
    "object": "the performance"
  },
  {
    "subject": "the degradation of performance",
    "predicate": "is due to",
    "object": "the extra overhead of memory indirection and non-contiguous block memory"
  },
  {
    "subject": "VLLM",
    "predicate": "generates",
    "object": "the new token"
  },
  {
    "subject": "VLLM",
    "predicate": "uses algorithm",
    "object": "PagedAttention"
  },
  {
    "subject": "PagedAttention algorithm",
    "predicate": "operates on",
    "object": "physical blocks 7 and 1"
  },
  {
    "subject": "the new token",
    "predicate": "is generated in",
    "object": "the first autoregressive decoding step"
  },
  {
    "subject": "4.3",
    "predicate": "shows",
    "object": "how PagedAttention and VLLM handle basic decoding algorithms"
  },
  {
    "subject": "PagedAttention and VLLM",
    "predicate": "handle",
    "object": "basic decoding algorithms"
  },
  {
    "subject": "basic decoding algorithms",
    "predicate": "include",
    "object": "greedy decoding and sampling"
  },
  {
    "subject": "greedy decoding and sampling",
    "predicate": "take",
    "object": "one user prompt as input"
  },
  {
    "subject": "greedy decoding and sampling",
    "predicate": "generate",
    "object": "a single output sequence"
  },
  {
    "subject": "the prompt",
    "predicate": "has",
    "object": "7 tokens"
  },
  {
    "subject": "VLLM",
    "predicate": "maps",
    "object": "the first 2 logical KV blocks (0 and 1) to 2 physical KV blocks (7 and 1, respectively)"
  },
  {
    "subject": "VLLM",
    "predicate": "generates",
    "object": "the KV cache of the prompts and the first output token"
  },
  {
    "subject": "VLLM",
    "predicate": "generates",
    "object": "the KV cache of the prompts and the first output token with a conventional self-attention algorithm"
  },
  {
    "subject": "VLLM",
    "predicate": "stores",
    "object": "the KV cache of the first 4 tokens in logical block 0"
  },
  {
    "subject": "VLLM",
    "predicate": "stores",
    "object": "the KV cache of the following 3 tokens in logical block 1"
  },
  {
    "subject": "VLLM",
    "predicate": "dynamically assigns",
    "object": "new physical blocks to logical blocks"
  },
  {
    "subject": "more tokens and their KV cache",
    "predicate": "are generated",
    "object": ""
  },
  {
    "subject": "VLLM",
    "predicate": "exhausts",
    "object": "free physical blocks for new tokens"
  },
  {
    "subject": "VLLM",
    "predicate": "selects",
    "object": "a set of sequences to evict"
  },
  {
    "subject": "VLLM",
    "predicate": "transfers",
    "object": "their KV cache to the CPU"
  },
  {
    "subject": "THE REMAINING SLOT",
    "predicate": "is reserved for",
    "object": "THE SUBSEQUENT AUTOREGRESSIVE GENERATION PHASE"
  },
  {
    "subject": "one slot",
    "predicate": "remains",
    "object": "available in the last logical block"
  },
  {
    "subject": "newly generated KV cache",
    "predicate": "is stored",
    "object": "there"
  },
  {
    "subject": "block tables filled record",
    "predicate": "is updated",
    "object": ""
  },
  {
    "subject": "VLLM",
    "predicate": "stores",
    "object": "newly generated KV cache in a new logical block"
  },
  {
    "subject": "VLLM",
    "predicate": "allocates",
    "object": "a new physical block (physical block 3)"
  },
  {
    "subject": "VLLM",
    "predicate": "stores",
    "object": "this mapping in the block table"
  },
  {
    "subject": "last logical block",
    "predicate": "is",
    "object": "full"
  },
  {
    "subject": "VLLM",
    "predicate": "concatenates",
    "object": "all the input tokens of the current iteration"
  },
  {
    "subject": "all tokens",
    "predicate": "are for",
    "object": "prompt phase four score and seven years ago our fathers brought"
  },
  {
    "subject": "block 0, block 1, block 2, block 3",
    "predicate": "are",
    "object": "physical KV blocks"
  },
  {
    "subject": "request A",
    "predicate": "is related to",
    "object": "request B"
  },
  {
    "subject": "figure 7",
    "predicate": "is",
    "object": "mentioned"
  },
  {
    "subject": "Storing multiple tokens within a KV block (block size 1)",
    "predicate": "enables",
    "object": "the PagedAttention kernel to process the KV cache across more positions in parallel"
  },
  {
    "subject": "Processing the KV cache across more positions in parallel",
    "predicate": "increases",
    "object": "hardware utilization"
  },
  {
    "subject": "Processing the KV cache across more positions in parallel",
    "predicate": "reduces",
    "object": "latency"
  },
  {
    "subject": "a larger block size",
    "predicate": "increases",
    "object": "memory fragmentation"
  },
  {
    "subject": "we",
    "predicate": "show",
    "object": "an example of VLLM managing the memory for two sequences"
  },
  {
    "subject": "THE LOGICAL BLOCKS OF THE TWO SEQUENCES",
    "predicate": "ARE MAPPED TO",
    "object": "DIFFERENT PHYSICAL BLOCKS"
  },
  {
    "subject": "DIFFERENT PHYSICAL BLOCKS",
    "predicate": "ARE WITHIN",
    "object": "THE SPACE RESERVED BY THE BLOCK ENGINE IN GPU WORKERS"
  },
  {
    "subject": "The neighboring logical blocks of both sequences",
    "predicate": "do not need to be",
    "object": "contiguous in physical GPU memory"
  },
  {
    "subject": "The space of physical blocks",
    "predicate": "can be effectively utilized by",
    "object": "both sequences"
  },
  {
    "subject": "LLM",
    "predicate": "generates",
    "object": "multiple sampled outputs for a single input prompt"
  },
  {
    "subject": "users",
    "predicate": "can choose",
    "object": "a favorite output from various candidates"
  },
  {
    "subject": "A request 616",
    "predicate": "samples",
    "object": "A1"
  },
  {
    "subject": "A1",
    "predicate": "refers to",
    "object": "four score and seven years ago"
  },
  {
    "subject": "Our fathers",
    "predicate": "are associated with",
    "object": "block 0"
  },
  {
    "subject": "Our mothers",
    "predicate": "are associated with",
    "object": "block 0"
  },
  {
    "subject": "Physical KV blocks",
    "predicate": "include",
    "object": "block 0"
  },
  {
    "subject": "Logical KV blocks",
    "predicate": "include",
    "object": "block 0"
  },
  {
    "subject": "A2",
    "predicate": "is a sample",
    "object": "copy-on-write"
  },
  {
    "subject": "Copy-on-write",
    "predicate": "has",
    "object": "ref count 2"
  },
  {
    "subject": "Figure 8",
    "predicate": "illustrates",
    "object": "the described blocks"
  },
  {
    "subject": "we",
    "predicate": "assume",
    "object": "the more general case in which a request generates multiple sequences"
  },
  {
    "subject": "one request",
    "predicate": "includes",
    "object": "multiple samples sharing the same input prompt"
  },
  {
    "subject": "multiple samples",
    "predicate": "share",
    "object": "the same input prompt"
  },
  {
    "subject": "the KV cache of the prompt",
    "predicate": "is shared",
    "object": "in parallel sampling"
  },
  {
    "subject": "all parallel sequences in a request",
    "predicate": "can share",
    "object": "the KV cache for the prompt"
  },
  {
    "subject": "8",
    "predicate": "shows",
    "object": "an example of parallel decoding for two outputs"
  },
  {
    "subject": "both outputs",
    "predicate": "share",
    "object": "the same prompt"
  },
  {
    "subject": "we",
    "predicate": "reserve space for",
    "object": "one copy of the prompt's state at the prompt phase"
  },
  {
    "subject": "the logical blocks for the prompts of both sequences",
    "predicate": "are mapped to",
    "object": "the same physical blocks"
  },
  {
    "subject": "the logical block 0 and 1 of both sequences",
    "predicate": "are mapped to",
    "object": "physical blocks 7 and 1, respectively"
  },
  {
    "subject": "a single physical block",
    "predicate": "can be mapped to",
    "object": "multiple logical blocks"
  },
  {
    "subject": "we",
    "predicate": "introduce",
    "object": "a reference count for each physical block"
  },
  {
    "subject": "reference counts for physical block 7",
    "predicate": "are",
    "object": "2"
  },
  {
    "subject": "the two outputs",
    "predicate": "sample",
    "object": "different output tokens"
  },
  {
    "subject": "the two outputs",
    "predicate": "need",
    "object": "separate storage for KV cache"
  },
  {
    "subject": "VLLM",
    "predicate": "recognizes",
    "object": "the reference count of the corresponding physical block (physical block 1) is greater than 1"
  },
  {
    "subject": "VLLM",
    "predicate": "instructs",
    "object": "the block engine to copy the information from physical block 1"
  },
  {
    "subject": "VLLM",
    "predicate": "decreases",
    "object": "the reference count to 1"
  },
  {
    "subject": "Sample A2",
    "predicate": "writes to",
    "object": "physical block 1"
  },
  {
    "subject": "The reference count",
    "predicate": "is reduced to",
    "object": "1"
  },
  {
    "subject": "A2",
    "predicate": "writes",
    "object": "newly generated KV cache to physical block 1"
  },
  {
    "subject": "sharing physical blocks across multiple samples",
    "predicate": "can",
    "object": "greatly reduce memory usage"
  },
  {
    "subject": "memory usage",
    "predicate": "is especially reduced for",
    "object": "long input prompts"
  },
  {
    "subject": "users",
    "predicate": "expect",
    "object": "the top-most appropriate translations output by the LLM"
  },
  {
    "subject": "LLM tasks like machine translation 59",
    "predicate": "include",
    "object": "machine translation"
  },
  {
    "subject": "Beam search 49",
    "predicate": "is widely used to decode",
    "object": "the most probable output sequence from an LLM"
  },
  {
    "subject": "Beam search 49",
    "predicate": "mitigates",
    "object": "the computational complexity of fully traversing the block"
  },
  {
    "subject": "Beam search",
    "predicate": "expands",
    "object": "each candidate sequence in the beam"
  },
  {
    "subject": "Beam search",
    "predicate": "considers",
    "object": "all possible tokens"
  },
  {
    "subject": "Beam search",
    "predicate": "computes",
    "object": "their respective probabilities using the LLM"
  },
  {
    "subject": "Beam search",
    "predicate": "retains",
    "object": "the top-most probable sequences out of candidates"
  },
  {
    "subject": "V",
    "predicate": "is",
    "object": "the vocabulary size"
  },
  {
    "subject": "THE ALGORITHM",
    "predicate": "RELIES ON",
    "object": "THE BEAM WIDTH PARAMETER"
  },
  {
    "subject": "THE BEAM WIDTH PARAMETER",
    "predicate": "DETERMINES",
    "object": "THE NUMBER OF TOP CANDIDATES RETAINED AT EVERY STEP"
  },
  {
    "subject": "Beam search",
    "predicate": "facilitates sharing",
    "object": "initial prompt blocks"
  },
  {
    "subject": "Beam search",
    "predicate": "facilitates sharing",
    "object": "other blocks across different candidates"
  },
  {
    "subject": "Sharing patterns",
    "predicate": "dynamically change",
    "object": "as the decoding process advances"
  },
  {
    "subject": "Sharing patterns",
    "predicate": "are similar to",
    "object": "the process tree in the OS created by compound forks"
  },
  {
    "subject": "VLLM",
    "predicate": "manages",
    "object": "the KV blocks for a beam search example with 4"
  },
  {
    "subject": "each candidate sequence",
    "predicate": "has used",
    "object": "4 full logical blocks prior to the iteration illustrated as the dotted line"
  },
  {
    "subject": "ALL BEAM CANDIDATES",
    "predicate": "SHARE",
    "object": "THE FIRST BLOCK 0 (I.E., PROMPT)"
  },
  {
    "subject": "CANDIDATE 3",
    "predicate": "digresses from",
    "object": "others from the second block"
  },
  {
    "subject": "all candidates",
    "predicate": "share",
    "object": "blocks 0, 1, 3"
  },
  {
    "subject": "candidates 0 and 1",
    "predicate": "share",
    "object": "block 6"
  },
  {
    "subject": "top-4 probable candidates",
    "predicate": "originate from",
    "object": "candidates 1 and 2"
  },
  {
    "subject": "original candidates 0 and 3",
    "predicate": "are no longer among",
    "object": "the top candidates"
  },
  {
    "subject": "their logical blocks",
    "predicate": "are",
    "object": "freed"
  },
  {
    "subject": "the reference counts of corresponding physical blocks",
    "predicate": "are",
    "object": "reduced"
  },
  {
    "subject": "VLLM",
    "predicate": "allocates",
    "object": "new physical blocks (blocks 9-12)"
  },
  {
    "subject": "new physical blocks (blocks 9-12)",
    "predicate": "store",
    "object": "the new KV cache from the new candidates"
  },
  {
    "subject": "Previous LLM serving systems",
    "predicate": "require",
    "object": "frequent memory copies of the KV cache across the beam candidates"
  },
  {
    "subject": "Candidate 3",
    "predicate": "would need to copy",
    "object": "a large portion of Candidate 2's KV cache"
  },
  {
    "subject": "Candidate 3",
    "predicate": "would need to copy a large portion of Candidate 2's KV cache",
    "object": "to continue generation"
  },
  {
    "subject": "most blocks of different beam candidates",
    "predicate": "can be shared",
    "object": "in VLLM"
  },
  {
    "subject": "THE SAME STRATEGY",
    "predicate": "is applied in",
    "object": "BEAM SEARCH"
  },
  {
    "subject": "THE SAME STRATEGY",
    "predicate": "is applied in",
    "object": "PREFIX SHARING BY VLLM"
  },
  {
    "subject": "THE COPY-ON-WRITE MECHANISM",
    "predicate": "is applied only when",
    "object": "the newly generated tokens are within an old shared block"
  },
  {
    "subject": "the newly generated tokens",
    "predicate": "are within",
    "object": "an old shared block"
  },
  {
    "subject": "the copy-on-write mechanism",
    "predicate": "is applied in",
    "object": "parallel decoding"
  },
  {
    "subject": "LLM user",
    "predicate": "provides",
    "object": "a (long) description of the task including instructions and example inputs and outputs"
  },
  {
    "subject": "a (long) description of the task including instructions and example inputs and outputs",
    "predicate": "is also known as",
    "object": "system prompt 36"
  },
  {
    "subject": "THE DESCRIPTION",
    "predicate": "is concatenated with",
    "object": "THE ACTUAL TASK INPUT"
  },
  {
    "subject": "THE DESCRIPTION AND THE ACTUAL TASK INPUT",
    "predicate": "form",
    "object": "THE PROMPT OF THE REQUEST"
  },
  {
    "subject": "SEA OTTER",
    "predicate": "translates to",
    "object": "LOUTRE DE MER"
  },
  {
    "subject": "PEPPERMINT",
    "predicate": "translates to",
    "object": "MENTHE POIVRE"
  },
  {
    "subject": "PLUSH GIRAFE",
    "predicate": "translates to",
    "object": "GIRAFE EN PELUCHE"
  },
  {
    "subject": "CHEESE",
    "predicate": "translates to",
    "object": "FROMAGE"
  },
  {
    "subject": "I LOVE YOU",
    "predicate": "translates to",
    "object": "JE T'AIME"
  },
  {
    "subject": "THE EXAMPLES",
    "predicate": "ARE ADOPTED FROM",
    "object": "5"
  },
  {
    "subject": "10",
    "predicate": "shows",
    "object": "an example"
  },
  {
    "subject": "the shared prefix",
    "predicate": "can be tuned via",
    "object": "prompt engineering"
  },
  {
    "subject": "tuning the shared prefix via prompt engineering",
    "predicate": "improves",
    "object": "the accuracy of the downstream tasks 26, 27"
  },
  {
    "subject": "many user prompts",
    "predicate": "share",
    "object": "a prefix"
  },
  {
    "subject": "the LLM service provider",
    "predicate": "can store",
    "object": "the KV cache of the prefix in advance"
  },
  {
    "subject": "storing the KV cache of the prefix in advance",
    "predicate": "reduces",
    "object": "the redundant computation spent on the prefix"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "reserving a set of physical blocks for a set of predefined shared prefixes by the LLM service provider"
  },
  {
    "subject": "OS",
    "predicate": "handles",
    "object": "shared library across processes"
  },
  {
    "subject": "A user input prompt with the shared prefix",
    "predicate": "can map",
    "object": "its logical blocks to the cached physical blocks"
  },
  {
    "subject": "The last block",
    "predicate": "is marked",
    "object": "copy-on-write"
  },
  {
    "subject": "THE PROMPT PHASE COMPUTATION",
    "predicate": "needs to execute on",
    "object": "the users task input"
  },
  {
    "subject": "THE DECODING METHODS DISCUSSED EARLIER",
    "predicate": "exhibit",
    "object": "DIVERSE MEMORY SHARING AND ACCESSING PATTERNS"
  },
  {
    "subject": "VLLM",
    "predicate": "facilitates",
    "object": "the simultaneous processing of requests with different decoding preferences"
  },
  {
    "subject": "existing systems",
    "predicate": "cannot do efficiently",
    "object": "the simultaneous processing of requests with different decoding preferences"
  },
  {
    "subject": "THE LLM AND ITS EXECUTION KERNEL",
    "predicate": "see",
    "object": "a list of physical block IDs for each sequence"
  },
  {
    "subject": "THE LLM AND ITS EXECUTION KERNEL",
    "predicate": "do not need to handle",
    "object": "sharing patterns across sequences"
  },
  {
    "subject": "this approach",
    "predicate": "broadens",
    "object": "the batching opportunities for requests with different sampling requirements"
  },
  {
    "subject": "this approach",
    "predicate": "increases",
    "object": "the system's overall throughput"
  },
  {
    "subject": "VLLM",
    "predicate": "must prioritize",
    "object": "a subset of requests when the request traffic surpasses the system's capacity"
  },
  {
    "subject": "VLLM",
    "predicate": "needs to preempt",
    "object": "requests"
  },
  {
    "subject": "VLLM",
    "predicate": "ensures",
    "object": "the earliest arrived requests are served first"
  },
  {
    "subject": "VLLM",
    "predicate": "ensures",
    "object": "the latest requests are preempted first"
  },
  {
    "subject": "VLLM",
    "predicate": "adopts",
    "object": "first-come-first-serve (FCFS) scheduling policy"
  },
  {
    "subject": "first-come-first-serve (FCFS) scheduling policy",
    "predicate": "applies to",
    "object": "all requests"
  },
  {
    "subject": "first-come-first-serve (FCFS) scheduling policy",
    "predicate": "ensures",
    "object": "fairness"
  },
  {
    "subject": "first-come-first-serve (FCFS) scheduling policy",
    "predicate": "prevents",
    "object": "starvation"
  },
  {
    "subject": "VLLM",
    "predicate": "can run out of",
    "object": "the GPUs physical blocks to store the newly generated KV cache"
  },
  {
    "subject": "block size",
    "predicate": "is",
    "object": "too small"
  },
  {
    "subject": "VLLM",
    "predicate": "may not fully utilize",
    "object": "the GPUs parallelism for reading and processing KV cache"
  },
  {
    "subject": "VLLM",
    "predicate": "needs to answer",
    "object": "two classic questions"
  },
  {
    "subject": "we",
    "predicate": "consider",
    "object": "two techniques: swapping"
  },
  {
    "subject": "Eviction policies",
    "predicate": "use",
    "object": "heuristics"
  },
  {
    "subject": "heuristics",
    "predicate": "predict",
    "object": "which block will be accessed furthest in the future"
  },
  {
    "subject": "Eviction policies",
    "predicate": "evict",
    "object": "that block"
  },
  {
    "subject": "all blocks of a sequence",
    "predicate": "are accessed",
    "object": "together"
  },
  {
    "subject": "we",
    "predicate": "implement",
    "object": "an all-or-nothing eviction policy"
  },
  {
    "subject": "all-or-nothing eviction policy",
    "predicate": "means",
    "object": "either evict all or none of the blocks of a sequence"
  },
  {
    "subject": "MULTIPLE SEQUENCES WITHIN ONE REQUEST",
    "predicate": "are",
    "object": "gang-scheduled as a sequence group"
  },
  {
    "subject": "sequences within one sequence group",
    "predicate": "are preempted or rescheduled together",
    "object": "true"
  },
  {
    "subject": "sequences within one sequence group",
    "predicate": "are preempted or rescheduled together",
    "object": "due to potential memory sharing across those sequences"
  },
  {
    "subject": "classic technique",
    "predicate": "is used by",
    "object": "most virtual memory implementations"
  },
  {
    "subject": "most virtual memory implementations",
    "predicate": "copy",
    "object": "evicted pages to a swap space on the disk"
  },
  {
    "subject": "we",
    "predicate": "copy",
    "object": "evicted blocks to the CPU memory"
  },
  {
    "subject": "VLLM",
    "predicate": "includes",
    "object": "a CPU block allocator"
  },
  {
    "subject": "CPU block allocator",
    "predicate": "manages",
    "object": "the physical blocks swapped to CPU RAM"
  },
  {
    "subject": "GPU block allocator",
    "predicate": "is part of",
    "object": "VLLM"
  },
  {
    "subject": "VLLM",
    "predicate": "preempts",
    "object": "a sequence"
  },
  {
    "subject": "VLLM",
    "predicate": "evicts",
    "object": "its blocks"
  },
  {
    "subject": "VLLM",
    "predicate": "stops accepting",
    "object": "new requests"
  },
  {
    "subject": "VLLM",
    "predicate": "stops accepting new requests until",
    "object": "all preempted sequences are completed"
  },
  {
    "subject": "a request",
    "predicate": "completes",
    "object": "once"
  },
  {
    "subject": "its blocks",
    "predicate": "are freed from",
    "object": "memory"
  },
  {
    "subject": "the blocks of a preempted sequence",
    "predicate": "are brought back in",
    "object": "to continue the processing of that sequence"
  },
  {
    "subject": "the number of blocks swapped to the CPU RAM",
    "predicate": "never exceeds",
    "object": "the number of total physical blocks in the GPU RAM"
  },
  {
    "subject": "the swap space on the CPU RAM",
    "predicate": "is bounded by",
    "object": "the GPU memory allocated for the KV cache"
  },
  {
    "subject": "we",
    "predicate": "recompute",
    "object": "the KV cache"
  },
  {
    "subject": "the KV cache",
    "predicate": "is recomputed when",
    "object": "the preempted sequences are rescheduled"
  },
  {
    "subject": "recomputation latency",
    "predicate": "can be",
    "object": "significantly lower than the original latency"
  },
  {
    "subject": "tokens generated at decoding",
    "predicate": "can be concatenated with",
    "object": "the original user prompt as a new prompt"
  },
  {
    "subject": "their KV cache at all positions",
    "predicate": "can be generated in",
    "object": "one prompt phase iteration"
  },
  {
    "subject": "performances of swapping and recomputation",
    "predicate": "depend on",
    "object": "bandwidth between CPU RAM and GPU memory"
  },
  {
    "subject": "performances of swapping and recomputation",
    "predicate": "depend on",
    "object": "computation power of the GPU"
  },
  {
    "subject": "We",
    "predicate": "examine",
    "object": "the speeds of swapping and recomputation in 7.3"
  },
  {
    "subject": "VLLM",
    "predicate": "supports",
    "object": "recomputation"
  },
  {
    "subject": "VLLM",
    "predicate": "supports",
    "object": "swapping"
  },
  {
    "subject": "recomputation and swapping",
    "predicate": "are",
    "object": "recovery mechanisms of VLLM"
  },
  {
    "subject": "many LLMs",
    "predicate": "have",
    "object": "parameter sizes exceeding the capacity of a single GPU"
  },
  {
    "subject": "a memory manager",
    "predicate": "is capable of handling",
    "object": "distributed memory"
  },
  {
    "subject": "VLLM",
    "predicate": "is effective in",
    "object": "distributed settings"
  },
  {
    "subject": "VLLM",
    "predicate": "supports",
    "object": "Megatron-LM style tensor model parallelism strategy on Transformers 47"
  },
  {
    "subject": "THIS STRATEGY",
    "predicate": "adheres to",
    "object": "AN SPMD (SINGLE PROGRAM MULTIPLE DATA) EXECUTION SCHEDULE"
  },
  {
    "subject": "THE LINEAR LAYERS",
    "predicate": "are partitioned",
    "object": "618"
  },
  {
    "subject": "THE DETAILED MODEL SIZES AND SERVER CONFIGURATIONS",
    "predicate": "are shown in",
    "object": "TABLE 1"
  },
  {
    "subject": "MODEL SIZE 13B",
    "predicate": "requires",
    "object": "GPUS A100 4"
  },
  {
    "subject": "MODEL SIZE 66B",
    "predicate": "requires",
    "object": "GPUS A100 8"
  },
  {
    "subject": "MODEL SIZE 175B",
    "predicate": "requires",
    "object": "GPUS A100-80GB 8"
  },
  {
    "subject": "MODEL SIZE 13B",
    "predicate": "has",
    "object": "TOTAL GPU MEMORY 40 GB"
  },
  {
    "subject": "MODEL SIZE 66B",
    "predicate": "has",
    "object": "TOTAL GPU MEMORY 160 GB"
  },
  {
    "subject": "MODEL SIZE 175B",
    "predicate": "has",
    "object": "TOTAL GPU MEMORY 640 GB"
  },
  {
    "subject": "MODEL SIZE 13B",
    "predicate": "has",
    "object": "PARAMETER SIZE 26 GB"
  },
  {
    "subject": "MODEL SIZE 66B",
    "predicate": "has",
    "object": "PARAMETER SIZE 132 GB"
  },
  {
    "subject": "MODEL SIZE 175B",
    "predicate": "has",
    "object": "PARAMETER SIZE 346 GB"
  },
  {
    "subject": "MODEL SIZE 13B",
    "predicate": "has",
    "object": "MEMORY FOR KV CACHE 12 GB"
  },
  {
    "subject": "MODEL SIZE 66B",
    "predicate": "has",
    "object": "MEMORY FOR KV CACHE 21 GB"
  },
  {
    "subject": "MODEL SIZE 175B",
    "predicate": "has",
    "object": "MEMORY FOR KV CACHE 264 GB"
  },
  {
    "subject": "GPUs",
    "predicate": "synchronize",
    "object": "intermediate results"
  },
  {
    "subject": "synchronize",
    "predicate": "method",
    "object": "all-reduce operation"
  },
  {
    "subject": "block-wise matrix multiplication",
    "predicate": "performed by",
    "object": "GPUs"
  },
  {
    "subject": "the attention operator",
    "predicate": "is split on",
    "object": "the attention head dimension"
  },
  {
    "subject": "each SPMD process",
    "predicate": "takes care of",
    "object": "a subset of attention heads in multi-head attention"
  },
  {
    "subject": "each model shard",
    "predicate": "processes",
    "object": "the same set of input tokens"
  },
  {
    "subject": "model parallel execution",
    "predicate": "is used",
    "object": "each model shard processes the same set of input tokens"
  },
  {
    "subject": "the same set of input tokens",
    "predicate": "requires",
    "object": "the KV cache for the same positions"
  },
  {
    "subject": "VLLM",
    "predicate": "features",
    "object": "a single KV cache manager within the centralized scheduler"
  },
  {
    "subject": "Different GPU workers",
    "predicate": "share",
    "object": "the manager"
  },
  {
    "subject": "Different GPU workers",
    "predicate": "share",
    "object": "the mapping from logical blocks to physical blocks"
  },
  {
    "subject": "THIS COMMON MAPPING",
    "predicate": "allows",
    "object": "GPU WORKERS to execute the model with the physical blocks provided by the scheduler for each input request"
  },
  {
    "subject": "the scheduler",
    "predicate": "prepares",
    "object": "the message with input token ids for each request in the batch"
  },
  {
    "subject": "the scheduler",
    "predicate": "prepares",
    "object": "the block table for each request"
  },
  {
    "subject": "THE SCHEDULER",
    "predicate": "BROADCASTS",
    "object": "THIS CONTROL MESSAGE TO THE GPU WORKERS"
  },
  {
    "subject": "GPU workers",
    "predicate": "send",
    "object": "sampled tokens of this iteration"
  },
  {
    "subject": "sampled tokens of this iteration",
    "predicate": "are sent back to",
    "object": "the scheduler"
  },
  {
    "subject": "GPU workers",
    "predicate": "start to execute",
    "object": "the model with the input token ids"
  },
  {
    "subject": "GPU workers",
    "predicate": "do not need to synchronize on",
    "object": "memory management"
  },
  {
    "subject": "GPU workers",
    "predicate": "need to receive",
    "object": "all the memory management information at the beginning of each decoding iteration along with the step inputs"
  },
  {
    "subject": "VLLM",
    "predicate": "is",
    "object": "an end-to-end serving system"
  },
  {
    "subject": "VLLM",
    "predicate": "has",
    "object": "a FastAPI frontend"
  },
  {
    "subject": "VLLM",
    "predicate": "has",
    "object": "a GPU-based inference engine"
  },
  {
    "subject": "THE FRONTEND",
    "predicate": "extends",
    "object": "THE OPENAI API 34 INTERFACE"
  },
  {
    "subject": "THE FRONTEND",
    "predicate": "allows",
    "object": "USERS to customize sampling parameters for each request"
  },
  {
    "subject": "sampling parameters",
    "predicate": "include",
    "object": "the maximum sequence length"
  },
  {
    "subject": "sampling parameters",
    "predicate": "include",
    "object": "the beam width"
  },
  {
    "subject": "THE VLLM ENGINE",
    "predicate": "is written in",
    "object": "8.5K lines of Python"
  },
  {
    "subject": "THE VLLM ENGINE",
    "predicate": "is written in",
    "object": "2K lines of CCUDA code"
  },
  {
    "subject": "model executor",
    "predicate": "implements",
    "object": "popular LLMs such as GPT 5, OPT 62, and LLAMA 52"
  },
  {
    "subject": "INPUT AND OUTPUT LENGTH DISTRIBUTIONS",
    "predicate": "are of",
    "object": "(A) SHAREGPT DATASET"
  },
  {
    "subject": "INPUT AND OUTPUT LENGTH DISTRIBUTIONS",
    "predicate": "are of",
    "object": "(B) ALPACA DATASET"
  },
  {
    "subject": "THE SHAREGPT DATASET",
    "predicate": "has longer input prompts than",
    "object": "THE ALPACA DATASET"
  },
  {
    "subject": "THE SHAREGPT DATASET",
    "predicate": "has longer output prompts than",
    "object": "THE ALPACA DATASET"
  },
  {
    "subject": "THE SHAREGPT DATASET",
    "predicate": "has higher variance than",
    "object": "THE ALPACA DATASET"
  },
  {
    "subject": "PYTORCH",
    "predicate": "version",
    "object": "39"
  },
  {
    "subject": "TRANSFORMERS",
    "predicate": "version",
    "object": "58"
  },
  {
    "subject": "WE",
    "predicate": "use",
    "object": "NCCL 32 for tensor communication across the distributed GPU workers"
  },
  {
    "subject": "PagedAttention",
    "predicate": "introduces",
    "object": "memory access patterns that are not efficiently supported by existing systems"
  },
  {
    "subject": "We",
    "predicate": "develop",
    "object": "several GPU kernels for optimizing PagedAttention"
  },
  {
    "subject": "The dynamic block mapping in PagedAttention",
    "predicate": "affects",
    "object": "the performance of the GPU operations involving the stored KV cache"
  },
  {
    "subject": "The GPU operations involving the stored KV cache",
    "predicate": "include",
    "object": "block readwrites and attention"
  },
  {
    "subject": "FUSED RE-SHAPE",
    "predicate": "and",
    "object": "BLOCK WRITE"
  },
  {
    "subject": "new KV cache",
    "predicate": "are split into",
    "object": "blocks"
  },
  {
    "subject": "blocks",
    "predicate": "are reshaped to",
    "object": "a memory layout optimized for block read"
  },
  {
    "subject": "new KV cache",
    "predicate": "are saved at positions specified by",
    "object": "the block table"
  },
  {
    "subject": "we",
    "predicate": "fuse",
    "object": "them into a single kernel"
  },
  {
    "subject": "fusing them into a single kernel",
    "predicate": "minimizes",
    "object": "kernel launch overheads"
  },
  {
    "subject": "we",
    "predicate": "implement",
    "object": "a kernel that batches the copy operations for different blocks into a single kernel launch"
  },
  {
    "subject": "We",
    "predicate": "adapt",
    "object": "the attention kernel in FasterTransformer 31"
  },
  {
    "subject": "the attention kernel in FasterTransformer 31",
    "predicate": "reads",
    "object": "KV cache according to the block table"
  },
  {
    "subject": "the attention kernel in FasterTransformer 31",
    "predicate": "performs",
    "object": "attention operations on the fly"
  },
  {
    "subject": "we",
    "predicate": "assign",
    "object": "a GPU warp to read each block"
  },
  {
    "subject": "assigning a GPU warp to read each block",
    "predicate": "ensures",
    "object": "coalesced memory access"
  },
  {
    "subject": "we",
    "predicate": "add support for",
    "object": "variable sequence lengths within a request batch"
  },
  {
    "subject": "BLOCK COPY OPERATIONS",
    "predicate": "are issued by",
    "object": "THE COPY-ON-WRITE MECHANISM"
  },
  {
    "subject": "BLOCK COPY OPERATIONS",
    "predicate": "may operate on",
    "object": "DISCONTINUOUS BLOCKS"
  },
  {
    "subject": "using the cudamemcpyasync API",
    "predicate": "can lead to",
    "object": "numerous invocations of small data movements"
  },
  {
    "subject": "VLLM",
    "predicate": "implements",
    "object": "various decoding algorithms"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "three key methods"
  },
  {
    "subject": "three key methods",
    "predicate": "are",
    "object": "fork, append, and free"
  },
  {
    "subject": "THE FORK METHOD",
    "predicate": "CREATES",
    "object": "A NEW SEQUENCE FROM AN EXISTING ONE"
  },
  {
    "subject": "THE APPEND METHOD",
    "predicate": "APPENDS",
    "object": "A NEW TOKEN TO THE SEQUENCE"
  },
  {
    "subject": "THE FREE METHOD",
    "predicate": "DELETES",
    "object": "THE SEQUENCE"
  },
  {
    "subject": "VLLM",
    "predicate": "creates",
    "object": "multiple output sequences"
  },
  {
    "subject": "VLLM",
    "predicate": "uses",
    "object": "the fork method"
  },
  {
    "subject": "multiple output sequences",
    "predicate": "are created from",
    "object": "the single input sequence"
  },
  {
    "subject": "parallel sampling",
    "predicate": "involves",
    "object": "VLLM creating multiple output sequences from the single input sequence using the fork method"
  },
  {
    "subject": "future decoding algorithms",
    "predicate": "can be supported by",
    "object": "combining these methods"
  },
  {
    "subject": "OPT-13B",
    "predicate": "uses",
    "object": "1 GPU"
  },
  {
    "subject": "OPT-13B",
    "predicate": "runs on",
    "object": "SHAREGPT"
  },
  {
    "subject": "OPT-66B",
    "predicate": "uses",
    "object": "4 GPUS"
  },
  {
    "subject": "OPT-66B",
    "predicate": "runs on",
    "object": "SHAREGPT"
  },
  {
    "subject": "OPT-175B",
    "predicate": "uses",
    "object": "8 GPUS"
  },
  {
    "subject": "OPT-175B",
    "predicate": "runs on",
    "object": "SHAREGPT"
  },
  {
    "subject": "OPT-13B",
    "predicate": "runs on",
    "object": "ALPACA"
  },
  {
    "subject": "OPT-66B",
    "predicate": "runs on",
    "object": "ALPACA"
  },
  {
    "subject": "OPT-175B",
    "predicate": "runs on",
    "object": "ALPACA"
  },
  {
    "subject": "Latency",
    "predicate": "is measured in",
    "object": "NORMALIZED LATENCY (STOKEN)"
  },
  {
    "subject": "Request rate",
    "predicate": "is measured in",
    "object": "REQUEST RATE (REQS)"
  },
  {
    "subject": "Latency methods",
    "predicate": "include",
    "object": "FASTERTRANSFORMER"
  },
  {
    "subject": "Latency methods",
    "predicate": "include",
    "object": "ORCA (MAX)"
  },
  {
    "subject": "Latency methods",
    "predicate": "include",
    "object": "ORCA (POW2)"
  },
  {
    "subject": "Latency methods",
    "predicate": "include",
    "object": "ORCA (ORACLE)"
  },
  {
    "subject": "Latency methods",
    "predicate": "include",
    "object": "VLLM"
  },
  {
    "subject": "A",
    "predicate": "has parallel size",
    "object": "2"
  },
  {
    "subject": "D",
    "predicate": "has beam width",
    "object": "2"
  },
  {
    "subject": "A",
    "predicate": "measures",
    "object": "request rate (reqs)"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "is a",
    "object": "method for normalized latency (stoken)"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "is a",
    "object": "method for normalized latency (stoken)"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "is a",
    "object": "method for normalized latency (stoken)"
  },
  {
    "subject": "VLLM",
    "predicate": "is a",
    "object": "method for normalized latency (stoken)"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "has batched requests",
    "object": "0, 5, 10, 15, 20, 25, 30, 35"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "has values",
    "object": "7.00, 9.81, 13.62, 30.42"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "has batched requests",
    "object": "0, 5, 10, 15, 20, 25, 30, 35"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "has values",
    "object": "7.00, 9.81, 13.62, 30.42"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "has batched requests",
    "object": "0, 5, 10, 15, 20, 25, 30, 35"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "has values",
    "object": "7.00, 9.81, 13.62, 30.42"
  },
  {
    "subject": "VLLM",
    "predicate": "has batched requests",
    "object": "0, 5, 10, 15, 20, 25, 30, 35"
  },
  {
    "subject": "VLLM",
    "predicate": "has values",
    "object": "7.00, 9.81, 13.62, 30.42"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "has batched requests",
    "object": "0, 25, 50, 75, 100, 125, 150"
  },
  {
    "subject": "ORCA (MAX)",
    "predicate": "has values",
    "object": "7.00, 43.24, 72.75, 132.44"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "has batched requests",
    "object": "0, 25, 50, 75, 100, 125, 150"
  },
  {
    "subject": "ORCA (POW2)",
    "predicate": "has values",
    "object": "7.00, 43.24, 72.75, 132.44"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "has batched requests",
    "object": "0, 25, 50, 75, 100, 125, 150"
  },
  {
    "subject": "ORCA (ORACLE)",
    "predicate": "has values",
    "object": "7.00, 43.24, 72.75, 132.44"
  },
  {
    "subject": "VLLM",
    "predicate": "has batched requests",
    "object": "0, 25, 50, 75, 100, 125, 150"
  },
  {
    "subject": "VLLM",
    "predicate": "has values",
    "object": "7.00, 43.24, 72.75, 132.44"
  },
  {
    "subject": "SINGLE SEQUENCE GENERATION",
    "predicate": "is performed with",
    "object": "OPT models"
  },
  {
    "subject": "SINGLE SEQUENCE GENERATION",
    "predicate": "is performed on",
    "object": "ShareGPT and Alpaca dataset"
  },
  {
    "subject": "WE",
    "predicate": "use",
    "object": "OPT 62 models with 13B parameters"
  },
  {
    "subject": "WE",
    "predicate": "use",
    "object": "OPT 62 models with 66B parameters"
  },
  {
    "subject": "WE",
    "predicate": "use",
    "object": "OPT 62 models with 175B parameters"
  },
  {
    "subject": "WE",
    "predicate": "use",
    "object": "LLAMA 52 with 13B parameters"
  },
  {
    "subject": "OPT 62 models",
    "predicate": "have",
    "object": "13B parameters"
  },
  {
    "subject": "OPT 62 models",
    "predicate": "have",
    "object": "66B parameters"
  },
  {
    "subject": "OPT 62 models",
    "predicate": "have",
    "object": "175B parameters"
  },
  {
    "subject": "LLAMA 52",
    "predicate": "has",
    "object": "13B parameters"
  },
  {
    "subject": "WE",
    "predicate": "use for",
    "object": "our evaluation"
  },
  {
    "subject": "13B",
    "predicate": "are",
    "object": "popular sizes for LLMs"
  },
  {
    "subject": "66B",
    "predicate": "are",
    "object": "popular sizes for LLMs"
  },
  {
    "subject": "13B and 66B",
    "predicate": "are shown in",
    "object": "an LLM leaderboard 38"
  },
  {
    "subject": "175B",
    "predicate": "is",
    "object": "the size of the famous GPT-3 5 model"
  },
  {
    "subject": "workloads",
    "predicate": "are synthesized based on",
    "object": "ShareGPT 51 and Alpaca 50 datasets"
  },
  {
    "subject": "ShareGPT 51 and Alpaca 50 datasets",
    "predicate": "contain",
    "object": "input and output texts of real LLM services"
  },
  {
    "subject": "THE SHAREGPT DATASET",
    "predicate": "is",
    "object": "a collection of user-shared conversations with ChatGPT"
  },
  {
    "subject": "We",
    "predicate": "synthesize",
    "object": "the chatting history and user query using the ShareGPT dataset"
  },
  {
    "subject": "THE ALPACA DATASET",
    "predicate": "is",
    "object": "an instruction dataset"
  },
  {
    "subject": "THE ALPACA DATASET",
    "predicate": "is generated by",
    "object": "GPT-3.5 with Self-Instruct 57"
  },
  {
    "subject": "We",
    "predicate": "tokenize",
    "object": "the datasets"
  },
  {
    "subject": "We",
    "predicate": "use",
    "object": "their input and output lengths"
  },
  {
    "subject": "We",
    "predicate": "use their input and output lengths to",
    "object": "synthesize client requests"
  },
  {
    "subject": "we",
    "predicate": "generate",
    "object": "request arrival times using Poisson distribution with different request rates"
  },
  {
    "subject": "these datasets",
    "predicate": "do not include",
    "object": "timestamps"
  },
  {
    "subject": "BASELINE 1",
    "predicate": "is",
    "object": "FASTERTRANSFORMER"
  },
  {
    "subject": "FASTERTRANSFORMER 31",
    "predicate": "is",
    "object": "a distributed inference engine highly optimized for latency"
  },
  {
    "subject": "FasterTransformer",
    "predicate": "does not have",
    "object": "its own scheduler"
  },
  {
    "subject": "We",
    "predicate": "implement",
    "object": "a custom scheduler"
  },
  {
    "subject": "a custom scheduler",
    "predicate": "has",
    "object": "a dynamic batching mechanism"
  },
  {
    "subject": "a dynamic batching mechanism",
    "predicate": "is similar to",
    "object": "the existing serving systems such as Triton 30"
  },
  {
    "subject": "we",
    "predicate": "set",
    "object": "a maximum batch size as large as possible for each experiment"
  },
  {
    "subject": "maximum batch size",
    "predicate": "is set according to",
    "object": "the GPU memory capacity"
  },
  {
    "subject": "the three ORCA baselines",
    "predicate": "behave",
    "object": "similarly"
  },
  {
    "subject": "ORCA 60",
    "predicate": "is",
    "object": "a state-of-the-art LLM serving system"
  },
  {
    "subject": "ORCA 60",
    "predicate": "is optimized for",
    "object": "throughput"
  },
  {
    "subject": "we",
    "predicate": "implement",
    "object": "our own version of ORCA"
  },
  {
    "subject": "ORCA",
    "predicate": "is",
    "object": "not publicly available for use"
  },
  {
    "subject": "We",
    "predicate": "implement",
    "object": "three versions of ORCA"
  },
  {
    "subject": "three versions of ORCA",
    "predicate": "are based on",
    "object": "how much it over-reserves the space for request outputs"
  },
  {
    "subject": "ORCA",
    "predicate": "is also known as",
    "object": "ORACLE"
  },
  {
    "subject": "ORCA",
    "predicate": "uses",
    "object": "the buddy allocation algorithm"
  },
  {
    "subject": "the buddy allocation algorithm",
    "predicate": "determines",
    "object": "the memory address to store KV cache"
  },
  {
    "subject": "the system",
    "predicate": "has",
    "object": "the knowledge of the lengths of the outputs that will be actually generated for the requests"
  },
  {
    "subject": "ORCA",
    "predicate": "has",
    "object": "upper-bound performance"
  },
  {
    "subject": "upper-bound performance of ORCA",
    "predicate": "is",
    "object": "infeasible to achieve in practice"
  },
  {
    "subject": "the system",
    "predicate": "over-reserves",
    "object": "the space for outputs by at most 2"
  },
  {
    "subject": "true output length",
    "predicate": "is",
    "object": "25"
  },
  {
    "subject": "the system",
    "predicate": "reserves",
    "object": "the space up to the maximum sequence length of the model"
  },
  {
    "subject": "the maximum sequence length of the model",
    "predicate": "is",
    "object": "2048 tokens"
  },
  {
    "subject": "We",
    "predicate": "focus on",
    "object": "serving throughput"
  },
  {
    "subject": "we",
    "predicate": "measure",
    "object": "normalized latency of the systems"
  },
  {
    "subject": "normalized latency of the systems",
    "predicate": "is",
    "object": "the mean of every request's end-to-end latency divided by its output length"
  },
  {
    "subject": "workloads",
    "predicate": "have",
    "object": "different request rates"
  },
  {
    "subject": "A HIGH-THROUGHPUT SERVING SYSTEM",
    "predicate": "should retain",
    "object": "low normalized latency against high request rates"
  },
  {
    "subject": "we",
    "predicate": "evaluate",
    "object": "the systems with 1-hour traces"
  },
  {
    "subject": "we",
    "predicate": "use",
    "object": "15-minute traces for the OPT-175B model as an exception"
  },
  {
    "subject": "reason",
    "predicate": "is",
    "object": "cost limit"
  },
  {
    "subject": "OPT-13B",
    "predicate": "is used on",
    "object": "the Alpaca dataset"
  },
  {
    "subject": "Parallel generation and beam search",
    "predicate": "are performed with",
    "object": "OPT-13B"
  },
  {
    "subject": "we",
    "predicate": "evaluate the performance of",
    "object": "VLLM with basic sampling (one sample per request)"
  },
  {
    "subject": "evaluation",
    "predicate": "is performed on",
    "object": "three models and two datasets"
  },
  {
    "subject": "12",
    "predicate": "shows",
    "object": "the results on the ShareGPT dataset"
  },
  {
    "subject": "13B",
    "predicate": "shows the results on",
    "object": "the Alpaca dataset"
  },
  {
    "subject": "the Alpaca dataset",
    "predicate": "follows a similar trend to",
    "object": "the ShareGPT dataset"
  },
  {
    "subject": "the curves",
    "predicate": "illustrate",
    "object": "that as the request rate increases, the latency initially increases at a gradual pace but then suddenly explodes"
  },
  {
    "subject": "the request rate",
    "predicate": "increases",
    "object": null
  },
  {
    "subject": "the latency",
    "predicate": "initially increases at",
    "object": "a gradual pace"
  },
  {
    "subject": "the latency",
    "predicate": "then explodes",
    "object": "suddenly"
  },
  {
    "subject": "request rate",
    "predicate": "surpasses",
    "object": "capacity of the serving system"
  },
  {
    "subject": "queue length",
    "predicate": "continues to grow",
    "object": "infinitely"
  },
  {
    "subject": "latency of the requests",
    "predicate": "continues to grow",
    "object": "infinitely"
  },
  {
    "subject": "VLLM",
    "predicate": "can sustain higher request rates compared to",
    "object": "ORCA (ORACLE)"
  },
  {
    "subject": "VLLM",
    "predicate": "can sustain 1.72 to 7 times higher request rates compared to",
    "object": "ORCA (ORACLE)"
  },
  {
    "subject": "VLLM",
    "predicate": "can sustain 2.78 times higher request rates compared to",
    "object": "ORCA (MAX)"
  },
  {
    "subject": "VLLM",
    "predicate": "maintains",
    "object": "similar latencies"
  },
  {
    "subject": "VLLM",
    "predicate": "performance measured on",
    "object": "ShareGPT dataset"
  },
  {
    "subject": "13A, FOR OPT-13B VLLM",
    "predicate": "processes",
    "object": "2.2 more requests at the same time than ORCA (ORACLE)"
  },
  {
    "subject": "13A, FOR OPT-13B VLLM",
    "predicate": "processes",
    "object": "4.3 more requests than ORCA (MAX)"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves",
    "object": "1.67 higher throughput than ORCA (Oracle) when the one-shot prefix is shared"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves higher throughput than",
    "object": "ORCA (Oracle)"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves throughput",
    "object": "3.58 higher"
  },
  {
    "subject": "VLLMS PAGEDATTENTION",
    "predicate": "can efficiently manage",
    "object": "the memory usage"
  },
  {
    "subject": "VLLMS PAGEDATTENTION",
    "predicate": "enable",
    "object": "batching more requests than ORCA"
  },
  {
    "subject": "The iteration-level scheduling in ORCA 60",
    "predicate": "is",
    "object": "a complementary technique to PagedAttention in VLLM"
  },
  {
    "subject": "Both systems",
    "predicate": "aim to increase",
    "object": "the GPU utilization"
  },
  {
    "subject": "Both systems",
    "predicate": "aim to increase",
    "object": "the throughput of LLM serving"
  },
  {
    "subject": "ORCA",
    "predicate": "achieves increased GPU utilization and throughput",
    "object": "by scheduling and interleaving the requests"
  },
  {
    "subject": "Scheduling and interleaving the requests in ORCA",
    "predicate": "allows",
    "object": "more requests to be processed in parallel"
  },
  {
    "subject": "VLLM",
    "predicate": "achieves increased GPU utilization and throughput",
    "object": "by increasing memory utilization"
  },
  {
    "subject": "Increasing memory utilization in VLLM",
    "predicate": "allows",
    "object": "the working sets of more requests to fit into memory"
  },
  {
    "subject": "VLLMS advantage over ORCA (ORACLE) and ORCA (POW2)",
    "predicate": "is",
    "object": "less pronounced"
  },
  {
    "subject": "The model and server configuration for OPT-175B",
    "predicate": "allows for",
    "object": "large GPU memory space available to store KV cache"
  },
  {
    "subject": "The Alpaca dataset",
    "predicate": "has",
    "object": "short sequences"
  },
  {
    "subject": "ORCA (ORACLE) and ORCA (POW2)",
    "predicate": "can batch",
    "object": "a large number of requests"
  },
  {
    "subject": "ORCA (ORACLE) and ORCA (POW2)",
    "predicate": "can batch requests despite",
    "object": "inefficiencies in their memory management"
  },
  {
    "subject": "OUTPUT SEQUENCES",
    "predicate": "values",
    "object": "2, 4, 6"
  },
  {
    "subject": "MEMORY SAVING (A) PARALLEL SAMPLING",
    "predicate": "values",
    "object": "6.09, 8.53, 9.79"
  },
  {
    "subject": "BEAM WIDTH",
    "predicate": "values",
    "object": "0, 20, 40, 60"
  },
  {
    "subject": "MEMORY SAVING (B) BEAM SEARCH",
    "predicate": "values",
    "object": "37.56, 53.13, 55.16"
  },
  {
    "subject": "FIGURE",
    "predicate": "number",
    "object": "15"
  },
  {
    "subject": "sharing KV blocks",
    "predicate": "results in",
    "object": "average amount of memory saving"
  },
  {
    "subject": "average amount of memory saving",
    "predicate": "occurs when serving",
    "object": "OPT-13B for the Alpaca trace"
  },
  {
    "subject": "memory sharing in page-dattention",
    "predicate": "is evaluated with",
    "object": "two popular sampling methods: parallel sampling and beam search"
  },
  {
    "subject": "WE",
    "predicate": "show",
    "object": "6.1 - 9.8 memory saving on parallel sampling"
  },
  {
    "subject": "WE",
    "predicate": "show",
    "object": "37.6 - 55.2 memory saving on beam search"
  },
  {
    "subject": "the same experiments with the ShareGPT dataset",
    "predicate": "showed",
    "object": "16.2 - 30.5 memory saving on parallel sampling"
  },
  {
    "subject": "the same experiments with the ShareGPT dataset",
    "predicate": "showed",
    "object": "44.3 - 66.3 memory saving on beam search"
  },
  {
    "subject": "VLLM",
    "predicate": "brings",
    "object": "more improvement over the ORCA baselines with a larger number of sequences to sample"
  },
  {
    "subject": "VLLM",
    "predicate": "can sustain",
    "object": "2 higher request rates compared to the three ORCA baselines"
  },
  {
    "subject": "14",
    "predicate": "shows",
    "object": "the results for beam search with different beam widths"
  },
  {
    "subject": "BEAM SEARCH",
    "predicate": "allows for",
    "object": "more sharing"
  },
  {
    "subject": "VLLM",
    "predicate": "demonstrates",
    "object": "even greater performance benefits"
  },
  {
    "subject": "VLLM",
    "predicate": "improves over",
    "object": "ORCA (Oracle) on OPT-13B and the Alpaca dataset"
  },
  {
    "subject": "Improvement of VLLM over ORCA",
    "predicate": "goes from",
    "object": "1.3 in basic sampling"
  },
  {
    "subject": "Improvement of VLLM over ORCA",
    "predicate": "goes to",
    "object": "2.3 in beam search with a width of 6"
  },
  {
    "subject": "15",
    "predicate": "plots",
    "object": "the amount of memory saving"
  },
  {
    "subject": "the amount of memory saving",
    "predicate": "is computed by",
    "object": "the number of blocks we saved by sharing divided by the number of total blocks without sharing"
  },
  {
    "subject": "VLLM",
    "predicate": "is explored for effectiveness",
    "object": "the case a prefix is shared among different input prompts"
  },
  {
    "subject": "input prompts",
    "predicate": "share",
    "object": "a common prefix"
  },
  {
    "subject": "THE PREFIX",
    "predicate": "includes",
    "object": "(A) 1 EXAMPLE WITH 80 TOKENS"
  },
  {
    "subject": "THE PREFIX",
    "predicate": "includes",
    "object": "(B) 5 EXAMPLES WITH 341 TOKENS"
  },
  {
    "subject": "the model",
    "predicate": "uses",
    "object": "LLAMA-13B 52"
  },
  {
    "subject": "LLAMA-13B 52",
    "predicate": "is",
    "object": "multilingual"
  },
  {
    "subject": "we",
    "predicate": "use",
    "object": "the WMT16 4 English-to-German translation dataset for the workload"
  },
  {
    "subject": "we",
    "predicate": "synthesize",
    "object": "two prefixes that include an instruction and a few translation examples"
  },
  {
    "subject": "The first prefix",
    "predicate": "includes",
    "object": "a single example (i.e., one-shot)"
  },
  {
    "subject": "The other prefix",
    "predicate": "includes",
    "object": "5 examples (i.e., few-shot)"
  },
  {
    "subject": "CHATBOT",
    "predicate": "is one of the most important applications of",
    "object": "LLMS"
  },
  {
    "subject": "we",
    "predicate": "let",
    "object": "the model generate a response"
  },
  {
    "subject": "the model",
    "predicate": "generate",
    "object": "a response"
  },
  {
    "subject": "a response",
    "predicate": "generated by concatenating",
    "object": "the chatting history and the last user query into a prompt"
  },
  {
    "subject": "OPT-13B model",
    "predicate": "has",
    "object": "limited context length"
  },
  {
    "subject": "we",
    "predicate": "cut",
    "object": "the prompt to the last 1024 tokens"
  },
  {
    "subject": "we",
    "predicate": "let the model generate",
    "object": "at most 1024 tokens"
  },
  {
    "subject": "We",
    "predicate": "do not store",
    "object": "the KV cache between different conversation rounds"
  },
  {
    "subject": "storing the KV cache between conversation rounds",
    "predicate": "would occupy",
    "object": "the space for other requests between the conversation rounds"
  },
  {
    "subject": "ShareGPT dataset",
    "predicate": "contains",
    "object": "many long conversations"
  },
  {
    "subject": "input prompts for most requests",
    "predicate": "have",
    "object": "1024 tokens"
  },
  {
    "subject": "ORCA baselines",
    "predicate": "reserve",
    "object": "space for 1024 tokens for the request outputs"
  },
  {
    "subject": "Buddy allocation algorithm",
    "predicate": "causes",
    "object": "ORCA baselines reserve the space for 1024 tokens for the request outputs"
  },
  {
    "subject": "VLLM",
    "predicate": "can effectively handle",
    "object": "64 128 256 context length"
  },
  {
    "subject": "VLLM",
    "predicate": "has latency measured in",
    "object": "kernel latency (us)"
  },
  {
    "subject": "Latency of attention kernels",
    "predicate": "is shown for",
    "object": "VLLM (BS 8), FT (BS 8), VLLM (BS 32), FT (BS 32)"
  },
  {
    "subject": "BLOCK SIZE",
    "predicate": "includes values",
    "object": "1, 2, 4, 8, 16, 32, 64, 128, 256"
  },
  {
    "subject": "NORMALIZED LATENCY (STOKEN)",
    "predicate": "includes values",
    "object": "0.0, 2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5"
  },
  {
    "subject": "SHAREGPT ALPACA (B)",
    "predicate": "measures",
    "object": "END-TO-END LATENCY"
  },
  {
    "subject": "END-TO-END LATENCY",
    "predicate": "varies with",
    "object": "DIFFERENT BLOCK SIZES"
  },
  {
    "subject": "we",
    "predicate": "study",
    "object": "various aspects of VLLM"
  },
  {
    "subject": "we",
    "predicate": "evaluate",
    "object": "the design choices we make with ablation experiments"
  },
  {
    "subject": "PagedAttention",
    "predicate": "resolves",
    "object": "the problem of memory fragmentation and reservation"
  },
  {
    "subject": "OUR GPU KERNELS (5)",
    "predicate": "involve",
    "object": "extra overheads of accessing the block table"
  },
  {
    "subject": "OUR GPU KERNELS (5)",
    "predicate": "involve",
    "object": "executing extra branches"
  },
  {
    "subject": "OUR GPU KERNELS (5)",
    "predicate": "involve",
    "object": "handling variable sequence lengths"
  },
  {
    "subject": "18A",
    "predicate": "leads to",
    "object": "2026 higher attention kernel latency"
  },
  {
    "subject": "2026 higher attention kernel latency",
    "predicate": "compared to",
    "object": "highly-optimized FasterTransformer implementation"
  },
  {
    "subject": "the overhead",
    "predicate": "is",
    "object": "small"
  },
  {
    "subject": "the overhead",
    "predicate": "only affects",
    "object": "the attention operator"
  },
  {
    "subject": "the overhead",
    "predicate": "does not affect",
    "object": "the other operators in the model, such as linear"
  },
  {
    "subject": "PagedAttention",
    "predicate": "makes",
    "object": "vLLM significantly outperform FasterTransformer in end-to-end performance"
  },
  {
    "subject": "choice of block size",
    "predicate": "can have",
    "object": "a substantial impact on the performance of VLLM"
  },
  {
    "subject": "block size",
    "predicate": "is",
    "object": "too large"
  },
  {
    "subject": "internal fragmentation",
    "predicate": "increases",
    "object": ""
  },
  {
    "subject": "probability of sharing",
    "predicate": "decreases",
    "object": ""
  },
  {
    "subject": "We",
    "predicate": "evaluate",
    "object": "the performance of VLLM with different block sizes"
  },
  {
    "subject": "We",
    "predicate": "use",
    "object": "the ShareGPT and Alpaca traces with basic sampling under fixed request rates"
  },
  {
    "subject": "block sizes from 16 to 128",
    "predicate": "lead to",
    "object": "the best performance"
  },
  {
    "subject": "block size 16 and 32",
    "predicate": "work well",
    "object": "in the Alpaca trace"
  },
  {
    "subject": "larger block sizes",
    "predicate": "significantly degrade",
    "object": "the performance"
  },
  {
    "subject": "the sequences",
    "predicate": "become",
    "object": "shorter than the block sizes"
  },
  {
    "subject": "block size 16",
    "predicate": "is large enough to",
    "object": "efficiently utilize the GPU"
  },
  {
    "subject": "block size 16",
    "predicate": "is small enough to",
    "object": "avoid significant internal fragmentation in most workloads"
  },
  {
    "subject": "VLLM",
    "predicate": "sets",
    "object": "its default block size as 16"
  },
  {
    "subject": "Time",
    "predicate": "measured in",
    "object": "milliseconds (ms)"
  },
  {
    "subject": "Microbenchmark",
    "predicate": "has block sizes",
    "object": "1, 2, 4, 8, 16, 32, 64, 128, 256"
  },
  {
    "subject": "Normalized latency",
    "predicate": "ranges from",
    "object": "0.0 to 2.5 (stoken)"
  },
  {
    "subject": "Figure 19",
    "predicate": "contains",
    "object": "Microbenchmark and End-to-End Performance data"
  },
  {
    "subject": "Performance metrics",
    "predicate": "include",
    "object": "Recompute, Swap In, Swap Out"
  },
  {
    "subject": "overhead",
    "predicate": "is for",
    "object": "recomputation and swapping"
  },
  {
    "subject": "overhead",
    "predicate": "varies with",
    "object": "different block sizes"
  },
  {
    "subject": "the overhead of recomputation",
    "predicate": "remains",
    "object": "constant across different block sizes"
  },
  {
    "subject": "recomputation",
    "predicate": "does not utilize",
    "object": "the KV blocks"
  },
  {
    "subject": "recomputation",
    "predicate": "is more efficient when",
    "object": "the block size is small"
  },
  {
    "subject": "swapping",
    "predicate": "is more efficient when",
    "object": "the block size is large"
  },
  {
    "subject": "recomputation overhead",
    "predicate": "is never higher than",
    "object": "20% of swapping's latency"
  },
  {
    "subject": "we",
    "predicate": "evaluate",
    "object": "their end-to-end performance"
  },
  {
    "subject": "we",
    "predicate": "microbenchmark",
    "object": "their overheads"
  },
  {
    "subject": "swapping",
    "predicate": "incurs",
    "object": "excessive overhead with small block sizes"
  },
  {
    "subject": "small block sizes",
    "predicate": "result in",
    "object": "numerous small data transfers between CPU and GPU"
  },
  {
    "subject": "numerous small data transfers between CPU and GPU",
    "predicate": "limit",
    "object": "the effective PCIe bandwidth"
  },
  {
    "subject": "the two methods",
    "predicate": "exhibit",
    "object": "comparable end-to-end performance for medium block sizes from 16 to 64"
  },
  {
    "subject": "VLLM",
    "predicate": "mitigates",
    "object": "the overhead of memory indirection in paging"
  },
  {
    "subject": "VLLM",
    "predicate": "mitigates the overhead by",
    "object": "fusing the GPU kernels for memory access operations with those for other operations such as attention"
  },
  {
    "subject": "Tensor shapes",
    "predicate": "are",
    "object": "typically static"
  },
  {
    "subject": "Memory allocation",
    "predicate": "can be",
    "object": "optimized ahead of time"
  },
  {
    "subject": "an increase in memory efficiency",
    "predicate": "may not result in",
    "object": "any performance improvement"
  },
  {
    "subject": "the performance",
    "predicate": "is",
    "object": "primarily compute-bound"
  },
  {
    "subject": "we",
    "predicate": "would be excited to see",
    "object": "VLLMs techniques being applied to other workloads with similar properties to LLM serving"
  },
  {
    "subject": "VLLM",
    "predicate": "re-interprets and augments",
    "object": "the idea of virtual memory and paging"
  },
  {
    "subject": "VLLM",
    "predicate": "leverages",
    "object": "the application-specific semantics"
  },
  {
    "subject": "VLLMS all-or-nothing swap-out policy",
    "predicate": "exploits",
    "object": "the fact that processing a request requires all of its corresponding token states to be stored in GPU memory"
  },
  {
    "subject": "recomputation method",
    "predicate": "is",
    "object": "another example"
  },
  {
    "subject": "recomputation method",
    "predicate": "recovers",
    "object": "evicted blocks"
  },
  {
    "subject": "recomputation method",
    "predicate": "is not feasible in",
    "object": "OS"
  },
  {
    "subject": "Model serving",
    "predicate": "has been",
    "object": "an active area of research in recent years"
  },
  {
    "subject": "Numerous systems",
    "predicate": "are proposed to tackle",
    "object": "diverse aspects of deep learning model deployment"
  },
  {
    "subject": "batching",
    "predicate": "is for",
    "object": "serving single or multiple models"
  },
  {
    "subject": "caching",
    "predicate": "is for",
    "object": "serving single or multiple models"
  },
  {
    "subject": "placement",
    "predicate": "is for",
    "object": "serving single or multiple models"
  },
  {
    "subject": "scheduling",
    "predicate": "is for",
    "object": "serving single or multiple models"
  },
  {
    "subject": "DVABATCH 12",
    "predicate": "introduces",
    "object": "multi-entry multi-exit batching"
  },
  {
    "subject": "REEF 21 AND SHEP-HERD 61",
    "predicate": "propose",
    "object": "preemption for serving"
  },
  {
    "subject": "ALPASERVE 28",
    "predicate": "utilizes",
    "object": "model parallelism for statistical multiplexing"
  },
  {
    "subject": "ALPASERVE",
    "predicate": "is",
    "object": "statistical multiplexing with model parallelism for deep learning serving"
  },
  {
    "subject": "general systems",
    "predicate": "fail to take into account",
    "object": "the auto-regressive property and token state of LLM inference"
  },
  {
    "subject": "SERVING SYSTEMS",
    "predicate": "are specialized for",
    "object": "TRANSFORMERS"
  },
  {
    "subject": "numerous specialized serving systems",
    "predicate": "have been developed for",
    "object": "the transformer architecture"
  },
  {
    "subject": "THESE SYSTEMS",
    "predicate": "utilize",
    "object": "GPU KERNEL OPTIMIZATIONS 1, 29, 31, 56"
  },
  {
    "subject": "THESE SYSTEMS",
    "predicate": "utilize",
    "object": "ADVANCED BATCHING MECHANISMS 14, 60"
  },
  {
    "subject": "THESE SYSTEMS",
    "predicate": "utilize",
    "object": "MODEL PARALLELISM 1, 41, 60"
  },
  {
    "subject": "THESE SYSTEMS",
    "predicate": "utilize",
    "object": "PARAMETER SHARING 64"
  },
  {
    "subject": "THESE SYSTEMS",
    "predicate": "utilize",
    "object": "efficient serving"
  },
  {
    "subject": "ORCA 60",
    "predicate": "is most relevant to",
    "object": "our approach"
  },
  {
    "subject": "fine-grained scheduling and interleaving of the requests like in ORCA",
    "predicate": "makes",
    "object": "memory management more challenging"
  },
  {
    "subject": "techniques proposed in VLLM",
    "predicate": "are",
    "object": "even more crucial"
  },
  {
    "subject": "The widening gap between the compute capability and memory capacity of accelerators",
    "predicate": "has caused",
    "object": "memory to become a bottleneck for both training and inference"
  },
  {
    "subject": "FLEXGEN 46",
    "predicate": "studies",
    "object": "how to swap weights and token states for LLM inference with 623 limited GPU memory"
  },
  {
    "subject": "FLEXGEN 46",
    "predicate": "does not target",
    "object": "the online serving settings"
  },
  {
    "subject": "OLLA 48",
    "predicate": "optimizes",
    "object": "the lifetime and location of tensors"
  },
  {
    "subject": "OLLA 48",
    "predicate": "reduces",
    "object": "fragmentation"
  },
  {
    "subject": "OLLA 48",
    "predicate": "does not do",
    "object": "fine-grained block-level management"
  },
  {
    "subject": "OLLA 48",
    "predicate": "does not do",
    "object": "online serving"
  },
  {
    "subject": "FLASHAT-TENTION 13",
    "predicate": "applies",
    "object": "tiling and kernel optimizations"
  },
  {
    "subject": "tiling and kernel optimizations",
    "predicate": "reduce",
    "object": "the peak memory of attention computation"
  },
  {
    "subject": "tiling and kernel optimizations",
    "predicate": "reduce",
    "object": "IO costs"
  },
  {
    "subject": "THIS PAPER",
    "predicate": "introduces",
    "object": "a new idea of block-level memory management in the context of online serving"
  },
  {
    "subject": "We",
    "predicate": "would like to thank",
    "object": "Xiaoxuan Liu"
  },
  {
    "subject": "We",
    "predicate": "would like to thank",
    "object": "Zhifeng Chen"
  },
  {
    "subject": "We",
    "predicate": "would like to thank",
    "object": "Yan-Ping Huang"
  },
  {
    "subject": "We",
    "predicate": "would like to thank",
    "object": "Anonymous SOSP reviewers"
  },
  {
    "subject": "We",
    "predicate": "would like to thank",
    "object": "our shepherd, Lidong Zhou"
  },
  {
    "subject": "Xiaoxuan Liu, Zhifeng Chen, Yan-Ping Huang, Anonymous SOSP reviewers, and our shepherd Lidong Zhou",
    "predicate": "provided",
    "object": "insightful feedback"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Andreessen Horowitz"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Anyscale"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Astronomer"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Google"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "IBM"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Intel"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Lacework"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Microsoft"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Mohamed Bin Zayed University of Artificial Intelligence"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Samsung SDS"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "Uber"
  },
  {
    "subject": "This research",
    "predicate": "is partly supported by",
    "object": "VMware"
  },
  {
    "subject": "REFERENCES",
    "predicate": "include authors",
    "object": "REZA YAZDANI AMINABADI, SAMYAM RAJBHANDARI, MINJIA ZHANG, AMMAR AHMAD AWAN, CHENG LI, DU LI, ELTON ZHENG, JEFF RASLEY, SHADEN SMITH, OLATUNJI RUWASE, ET AL."
  },
  {
    "subject": "DEEPSPEED INFERENCE",
    "predicate": "enables",
    "object": "efficient inference of transformer models at unprecedented scale"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:1607.06450"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:1607.06450",
    "predicate": "was published in",
    "object": "2016"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2107.03374"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2107.03374",
    "predicate": "was published in",
    "object": "2021"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:1604.06174"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:1604.06174",
    "predicate": "was published in",
    "object": "2016"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "identifier",
    "object": "ARXIV:2204.02311"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2204.02311",
    "predicate": "year",
    "object": "2022"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2302.11665"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2302.11665",
    "predicate": "published in year",
    "object": "2023"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "identifier",
    "object": "ARXIV:1712.06139"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:1712.06139",
    "predicate": "year",
    "object": "2017"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2303.06865"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2303.06865",
    "predicate": "published in year",
    "object": "2023"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:1909.08053"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:1909.08053",
    "predicate": "was published in",
    "object": "2019"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2302.13971"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2302.13971",
    "predicate": "publication year",
    "object": "2023"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2212.10560"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2212.10560",
    "predicate": "publication year",
    "object": "2022"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "identifier",
    "object": "ARXIV:1609.08144"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:1609.08144",
    "predicate": "year",
    "object": "2016"
  },
  {
    "subject": "ARXIV PREPRINT",
    "predicate": "has identifier",
    "object": "ARXIV:2205.01068"
  },
  {
    "subject": "ARXIV PREPRINT ARXIV:2205.01068",
    "predicate": "publication year",
    "object": "2022"
  },
  {
    "subject": "YOSHUA BENGIO",
    "predicate": "is an author with",
    "object": "RJEAN DUCHARME"
  },
  {
    "subject": "YOSHUA BENGIO",
    "predicate": "is an author with",
    "object": "PASCAL VINCENT"
  },
  {
    "subject": "RJEAN DUCHARME",
    "predicate": "is an author with",
    "object": "PASCAL VINCENT"
  },
  {
    "subject": "A NEURAL PROBABILISTIC LANGUAGE MODEL",
    "predicate": "is",
    "object": "a model"
  },
  {
    "subject": "4 OND REJ BOJAR",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "RAJEN CHATTERJEE",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "CHRISTIAN FEDERMANN",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "YVETTE GRAHAM",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "BARRY HADDOW",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MATTHIAS HUCK",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "ANTONIO JIMENO YEPES",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "PHILIPP KOEHN",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "VARVARA LOGACHEVA",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "CHRISTOF MONZ",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MATTEO NEGRI",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "AURELIE NEVEOL",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MARIANA NEVES",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MARTIN POPEL",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MATT POST",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "RAPHAEL RUBINO",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "CAROLINA SCARTON",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "LUCIA SPECIA",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MARCO TURCHI",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "KARIN VERSPOOR",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "MARCOS ZAMPIERI",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS",
    "predicate": "is located in",
    "object": "BERLIN"
  },
  {
    "subject": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS",
    "predicate": "is located in",
    "object": "GERMANY"
  },
  {
    "subject": "ASSOCIATION FOR COMPUTATIONAL LINGUISTICS",
    "predicate": "has identifier",
    "object": "131198"
  },
  {
    "subject": "HTTP:WWW.ACLWEB.ORGANTHOLOGYWW16W16-2301",
    "predicate": "has authors",
    "object": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al."
  },
  {
    "subject": "Language models",
    "predicate": "are",
    "object": "few-shot learners"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35",
    "predicate": "is published in",
    "object": "2022"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35",
    "predicate": "has page range",
    "object": "16344-16359"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS",
    "predicate": "is volume",
    "object": "27"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 27",
    "predicate": "was published in",
    "object": "2014"
  },
  {
    "subject": "14 JIARUI FANG",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "YANG YU",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "CHENGDUO ZHAO",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "JIE ZHOU",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "64",
    "predicate": "is associated with",
    "object": "ZHE ZHOU"
  },
  {
    "subject": "64",
    "predicate": "is associated with",
    "object": "XUECHAO WEI"
  },
  {
    "subject": "64",
    "predicate": "is associated with",
    "object": "JIEJING ZHANG"
  },
  {
    "subject": "64",
    "predicate": "is associated with",
    "object": "GUANGYU SUN"
  },
  {
    "subject": "Training deep nets",
    "predicate": "has",
    "object": "sublinear memory cost"
  },
  {
    "subject": "VICUNA",
    "predicate": "is",
    "object": "an open-source chatbot"
  },
  {
    "subject": "VICUNA",
    "predicate": "is impressing",
    "object": "GPT-4"
  },
  {
    "subject": "VICUNA",
    "predicate": "has",
    "object": "90 ChatGPT quality"
  },
  {
    "subject": "ORGBLOG2023-03-30-VICUNA 9",
    "predicate": "has authors",
    "object": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al."
  },
  {
    "subject": "PALM",
    "predicate": "is about",
    "object": "scaling language modeling with Pathways"
  },
  {
    "subject": "INFERLINE",
    "predicate": "is about",
    "object": "latency-aware provisioning and scaling for prediction serving pipelines"
  },
  {
    "subject": "Proceedings",
    "predicate": "are of",
    "object": "the 11th ACM Symposium on Cloud Computing"
  },
  {
    "subject": "CLIPPER",
    "predicate": "is",
    "object": "a low-latency online prediction serving system"
  },
  {
    "subject": "DVABATCH",
    "predicate": "is",
    "object": "DIVERSITY-AWARE MULTI-ENTRY MULTI-EXIT BATCHING"
  },
  {
    "subject": "DVABATCH",
    "predicate": "is used for",
    "object": "EFFICIENT PROCESSING OF DNN SERVICES ON GPUS"
  },
  {
    "subject": "USENIX ANNUAL TECHNICAL CONFERENCE",
    "predicate": "occurred in",
    "object": "2022"
  },
  {
    "subject": "USENIX ANNUAL TECHNICAL CONFERENCE",
    "predicate": "abbreviation",
    "object": "USENIX ATC 22"
  },
  {
    "subject": "USENIX ANNUAL TECHNICAL CONFERENCE",
    "predicate": "abbreviated as",
    "object": "USENIX ATC 22"
  },
  {
    "subject": "TURBOTRANSFORMERS",
    "predicate": "is",
    "object": "an efficient GPU serving system for transformer models"
  },
  {
    "subject": "26TH ACM SIGPLAN SYMPOSIUM",
    "predicate": "is on",
    "object": "PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING"
  },
  {
    "subject": "Proceedings",
    "predicate": "are of",
    "object": "the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming"
  },
  {
    "subject": "FASTAPI",
    "predicate": "is",
    "object": "15"
  },
  {
    "subject": "FASTAPI",
    "predicate": "is",
    "object": "a web framework"
  },
  {
    "subject": "URL",
    "predicate": "is",
    "object": "https://github.com/tiangolo/fastapi"
  },
  {
    "subject": "17 AMIR GHOLAMI",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "ZHEWEI YAO",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "SEHOON KIM",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "MICHAEL W MAHONEY",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "KURT KEUTZER",
    "predicate": "is an author",
    "object": "the text"
  },
  {
    "subject": "18",
    "predicate": "is associated with",
    "object": "GITHUB"
  },
  {
    "subject": "GitHub Copilot",
    "predicate": "is a feature of",
    "object": "GitHub"
  },
  {
    "subject": "GitHub Copilot",
    "predicate": "is associated with",
    "object": "Google"
  },
  {
    "subject": "HTTPS:BARD.GOOGLE.COM",
    "predicate": "has authors",
    "object": "Arpan Gujarati, Reza Karimi, Safya Alzayat, Wei Hao, Antoine Kaufmann, Ymir Vigfusson, Jonathan Mace"
  },
  {
    "subject": "MICROSECOND-SCALE PREEMPTION",
    "predicate": "is for",
    "object": "CONCURRENT GPU-ACCELERATED DNN INFERENCES"
  },
  {
    "subject": "DEEP RESIDUAL LEARNING",
    "predicate": "is used for",
    "object": "IMAGE RECOGNITION"
  },
  {
    "subject": "SWAPADVISOR",
    "predicate": "pushes",
    "object": "deep learning beyond the GPU memory limit via smart swapping"
  },
  {
    "subject": "The twenty-fifth international conference",
    "predicate": "is on",
    "object": "Architectural Support for Programming Languages and Operating Systems"
  },
  {
    "subject": "24 PARAS JAIN",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "AJAY JAIN",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "ANIRUDDHA NRUSIMHA",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "AMIR GHOLAMI",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "PIETER ABBEEL",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "JOSEPH GONZALEZ",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "KURT KEUTZER",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "ION STOICA",
    "predicate": "is a person",
    "object": "true"
  },
  {
    "subject": "25",
    "predicate": "includes authors",
    "object": "TOM KILBURN"
  },
  {
    "subject": "25",
    "predicate": "includes authors",
    "object": "DAVID BG EDWARDS"
  },
  {
    "subject": "25",
    "predicate": "includes authors",
    "object": "MICHAEL J LANIGAN"
  },
  {
    "subject": "25",
    "predicate": "includes authors",
    "object": "FRANK H SUMNER"
  },
  {
    "subject": "The power of scale",
    "predicate": "is for",
    "object": "parameter-efficient prompt tuning"
  },
  {
    "subject": "RAMMER",
    "predicate": "enables",
    "object": "holistic deep learning compiler optimizations with rTasks"
  },
  {
    "subject": "NVIDIA",
    "predicate": "is",
    "object": "30"
  },
  {
    "subject": "NVIDIA",
    "predicate": "is",
    "object": "31"
  },
  {
    "subject": "32",
    "predicate": "is associated with",
    "object": "NVIDIA"
  },
  {
    "subject": "NVIDIA Triton Inference Server",
    "predicate": "website",
    "object": "https://developer.nvidia.com"
  },
  {
    "subject": "FASTERTRANSFORMER",
    "predicate": "is hosted on",
    "object": "https://github.com/NVIDIA/FASTERTRANSFORMER"
  },
  {
    "subject": "NCCL",
    "predicate": "is",
    "object": "THE NVIDIA COLLECTIVE COMMUNICATION LIBRARY"
  },
  {
    "subject": "TENSORFLOW-SERVING",
    "predicate": "is",
    "object": "flexible, high-performance ML serving"
  },
  {
    "subject": "OPENAI",
    "predicate": "is",
    "object": "34"
  },
  {
    "subject": "ARXIV:2303.08774",
    "predicate": "has category",
    "object": "CS.CL"
  },
  {
    "subject": "ARXIV:2303.08774",
    "predicate": "has number",
    "object": "38"
  },
  {
    "subject": "ARXIV:2303.08774",
    "predicate": "associated with",
    "object": "LMSYS ORG"
  },
  {
    "subject": "CHATBOT ARENA LEADERBOARD WEEK 8",
    "predicate": "introduces",
    "object": "MT-BENCH and VICUNA-33B"
  },
  {
    "subject": "39",
    "predicate": "includes authors",
    "object": "ADAM PASZKE, SAM GROSS, FRANCISCO MASSA, ADAM LERER, JAMES BRADBURY, GREGORY CHANAN, TREVOR KILLEEN, ZEMING LIN, NATALIA GIMELSHEIN, LUCA ANTIGA, ET AL."
  },
  {
    "subject": "PYTORCH",
    "predicate": "is",
    "object": "an imperative style, high-performance deep learning library"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS",
    "predicate": "is volume",
    "object": "32"
  },
  {
    "subject": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32",
    "predicate": "was published in",
    "object": "2019"
  },
  {
    "subject": "POET",
    "predicate": "is about",
    "object": "training neural networks on tiny devices with integrated rematerialization and paging"
  },
  {
    "subject": "PMLR",
    "predicate": "has identifier",
    "object": "1757317583"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "REINER POPE"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "SHOLTO DOUGLAS"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "AAKANKSHA CHOWDHERY"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "JACOB DEVLIN"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "JAMES BRADBURY"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "ANSELM LEVSKAYA"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "JONATHAN HEEK"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "KEFAN XIAO"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "SHIVANI AGRAWAL"
  },
  {
    "subject": "41",
    "predicate": "includes",
    "object": "JEFF DEAN"
  },
  {
    "subject": "Amazon Web Services",
    "predicate": "is mentioned in",
    "object": "https://www.reuters.com/technology/tech-giants-ai-like-bing-bard-poses-billion-dollar-search-problem-2023-02-22"
  },
  {
    "subject": "Authors",
    "predicate": "include",
    "object": "Haichen Shen, Lequn Chen, Yuchen Jin, Liangyu Zhao, Bingyu Kong, Matthai Philipose, Arvind Krishnamurthy, and Ravi Sundaram"
  },
  {
    "subject": "Website",
    "predicate": "is",
    "object": "https://aws.amazon.com/bedrock"
  },
  {
    "subject": "NEXUS",
    "predicate": "is",
    "object": "a GPU cluster engine"
  },
  {
    "subject": "NEXUS",
    "predicate": "purpose",
    "object": "accelerating DNN-based video analysis"
  },
  {
    "subject": "HIGH-THROUGHPUT GENERATIVE INFERENCE",
    "predicate": "is performed on",
    "object": "LARGE LANGUAGE MODELS with a SINGLE GPU"
  },
  {
    "subject": "MEGATRON-LM",
    "predicate": "is used for",
    "object": "training multi-billion parameter language models using model parallelism"
  },
  {
    "subject": "OLLA",
    "predicate": "optimizes",
    "object": "the lifetime and location of arrays"
  },
  {
    "subject": "optimizing the lifetime and location of arrays",
    "predicate": "reduces",
    "object": "the memory usage of neural networks"
  },
  {
    "subject": "DOI",
    "predicate": "is",
    "object": "10.48550/ARXIV.2210.12924"
  },
  {
    "subject": "Authors",
    "predicate": "include",
    "object": "Ilya Sutskever"
  },
  {
    "subject": "Authors",
    "predicate": "include",
    "object": "Oriol Vinyals"
  },
  {
    "subject": "Authors",
    "predicate": "include",
    "object": "Quoc V Le"
  },
  {
    "subject": "STANFORD ALPACA",
    "predicate": "is",
    "object": "an instruction-following LLaMA model"
  },
  {
    "subject": "HTTPS",
    "predicate": "is",
    "object": "GITHUB.COM/TATSU-LAB/STANFORD-ALPACA"
  },
  {
    "subject": "HUGO TOUVRON",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "THIBAUT LAVRIL",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "GAUTIER IZACARD",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "XAVIER MARTINET",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "MARIE-ANNE LACHAUX",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "TIMOTHE LACROIX",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "BAPTISTE ROZIRE",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "NAMAN GOYAL",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "ERIC HAMBRO",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "FAISAL AZHAR",
    "predicate": "is listed at",
    "object": "HTTPS:SHAREGPT.COM 52"
  },
  {
    "subject": "LLAMA",
    "predicate": "is",
    "object": "open and efficient foundation language models"
  },
  {
    "subject": "PACMAN",
    "predicate": "is",
    "object": "an efficient compaction approach"
  },
  {
    "subject": "PACMAN",
    "predicate": "is for",
    "object": "log-structured key-value store"
  },
  {
    "subject": "log-structured key-value store",
    "predicate": "is on",
    "object": "persistent memory"
  },
  {
    "subject": "SUPERNEURONS",
    "predicate": "is about",
    "object": "dynamic GPU memory management for training deep neural networks"
  },
  {
    "subject": "LIGHTSEQ",
    "predicate": "is",
    "object": "a high performance inference library for transformers"
  },
  {
    "subject": "Proceedings",
    "predicate": "of",
    "object": "the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers"
  },
  {
    "subject": "SELF-INSTRUCT",
    "predicate": "is about",
    "object": "aligning language model with self generated instructions"
  },
  {
    "subject": "Google's Neural Machine Translation System",
    "predicate": "bridges",
    "object": "the gap between human and machine translation"
  },
  {
    "subject": "ORCA",
    "predicate": "is",
    "object": "a distributed serving system for transformer-based generative models"
  },
  {
    "subject": "Susan Zhang",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Stephen Roller",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Naman Goyal",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Mikel Artetxe",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Moya Chen",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Shuohui Chen",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Christopher Dewan",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Mona Diab",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Xian Li",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "Xi Victoria Lin",
    "predicate": "is a presenter at",
    "object": "NSDI23 conference"
  },
  {
    "subject": "OPT",
    "predicate": "is",
    "object": "OPEN PRE-TRAINED TRANSFORMER LANGUAGE MODELS"
  },
  {
    "subject": "ALPA",
    "predicate": "automates",
    "object": "inter-operator parallelism"
  },
  {
    "subject": "ALPA",
    "predicate": "automates",
    "object": "intra-operator parallelism"
  },
  {
    "subject": "ALPA",
    "predicate": "is used for",
    "object": "distributed deep learning"
  },
  {
    "subject": "PETS",
    "predicate": "is",
    "object": "A unified framework for parameter-efficient transformers serving"
  }
]